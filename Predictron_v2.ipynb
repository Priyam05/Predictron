{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distributions and Modules\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalization(df):\n",
    "    df.iloc[:,2:]= df.iloc[:,2:].apply(lambda x: ((x-x.mean()) / (x.std())))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(path):\n",
    "    df = pd.read_csv(path, header=None, delimiter=' ')\n",
    "    \n",
    "    #Normalize the data\n",
    "    df = Normalization(df)\n",
    "    \n",
    "    #Drop the columns which has all values as Nan\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    \n",
    "    #Get Rewards for each time step : 0 except last time step where reward is -100\n",
    "    df['Counter'] = df.index\n",
    "    lastRowIndex = df.groupby(0).last().Counter.tolist()\n",
    "    df['reward'] = df['Counter'].apply(lambda x : -100 if x in lastRowIndex else 0 )\n",
    "    df.drop(columns=['Counter'],inplace=True)\n",
    "    \n",
    "    #Rename columns\n",
    "    df.rename(columns={0: \"machine\", 1: \"time\"}, inplace=True)\n",
    "    \n",
    "    #Calculate Monte Carlo Value for each row\n",
    "    df1 = df.groupby('machine').last()[['time']].reset_index()\n",
    "    df = pd.merge(df, df1, on = 'machine', how = 'left').rename(columns ={'time_x':'time','time_y':'lastTimeStamp'})\n",
    "    df['MC_Val'] = (gamma ** (df['lastTimeStamp'] - df['time'] )) * (-100)\n",
    "    df = df.drop(columns='lastTimeStamp')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing(\"/home/abc/Berkeley/Prof_Ram/CMAPSSData/train_FD001.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have added the reward and Val column. We will be using the Val column for the Monte Carlo return gamma**(T-t)  X  -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets build the Neural network for the predictron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network for Observation - Hidden State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_OH(nn.Module):\n",
    "    def __init__(self, input_size, out_size):\n",
    "        super(NN_OH,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,64)\n",
    "        self.fc2 = nn.Linear(64,64)\n",
    "        self.fc3 = nn.Linear(64,out_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN_OH(\n",
      "  (fc1): Linear(in_features=24, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size  = 24\n",
    "out_size = 4\n",
    "net = NN_OH(input_size, out_size)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network for Hidden State - Reward & Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_reward_val(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NN_reward_val,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,32)\n",
    "        self.fc2 = nn.Linear(32,16)\n",
    "        self.fc3 = nn.Linear(16,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Neural Network which will take my current hidden state to the next hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_HH(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NN_HH,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,32)\n",
    "        self.fc2 = nn.Linear(32,32)\n",
    "        self.fc3 = nn.Linear(32,input_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have all the required neural networks for the predictron. Lets build the Predictron\n",
    "\n",
    "class Predictronv2(nn.Module):\n",
    "    def __init__(self, obs_size, hid_size, k=10):\n",
    "        super(Predictronv2,self).__init__()\n",
    "        \n",
    "        #Instantiate Neural Network for Observation-Hidden State\n",
    "        self.fc1 = NN_OH(obs_size, hid_size)\n",
    "        \n",
    "        #Instantiate Neural Network for Hidden State - Reward, Value\n",
    "        self.fc2 = NN_reward_val(hid_size)\n",
    "        \n",
    "        #Instantiate Neural Network for Hidden State - Next Hidden State\n",
    "        self.fc3 = NN_HH(hid_size)\n",
    "        \n",
    "        #K-step return\n",
    "        self.k = k\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Predictron core will output the value estimate for the current observation. We will input x (observation) \n",
    "        #and get value estimate. This implementation is for a k-step return which can be extended to TD(lambda) return\n",
    "        \n",
    "        #First step: Get the Hidden state for the current observation\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        #Unlike v1, we want to keep track of all the k-step returns till k and then take average\n",
    "        reward = self.fc2(x)[:,0]\n",
    "        all_k_vals = torch.zeros((x.shape[0],k+1))\n",
    "        all_k_vals[:,0] = reward #This will be the 0-step return\n",
    "        for i in range(1, self.k+1):\n",
    "            #Take the next step\n",
    "            x = self.fc3(x)\n",
    "            val_ith = (gamma**i)*self.fc2(x)[:,1]\n",
    "            #print(val_ith.shape, all_k_vals[:,i].shape, reward.shape)\n",
    "            all_k_vals[:,i] = reward + val_ith \n",
    "            reward += (gamma**(i))*(self.fc2(x))[:,0]      \n",
    "\n",
    "        return (torch.sum(all_k_vals, dim=1)/self.k).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXY(data):\n",
    "    x = torch.tensor(data.iloc[:, 2:-2].values).float()\n",
    "    y_target = torch.tensor(data.iloc[:,-1].values).float()\n",
    "    y_target = y_target.reshape(-1,1)\n",
    "    \n",
    "    return x, y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y_target = getXY(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20631, 1])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the loss function and Initialising the Predictron core\n",
    "k=10\n",
    "loss_fn = nn.MSELoss()\n",
    "core = Predictronv2(x.shape[1], 4, k)\n",
    "optimizer = optim.Adam(core.parameters(), lr = 1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after:0 iterations is :tensor(56.0966, grad_fn=<MseLossBackward>)\n",
      "Loss after:1 iterations is :tensor(0.8251, grad_fn=<MseLossBackward>)\n",
      "Loss after:2 iterations is :tensor(37.5112, grad_fn=<MseLossBackward>)\n",
      "Loss after:3 iterations is :tensor(11.2504, grad_fn=<MseLossBackward>)\n",
      "Loss after:4 iterations is :tensor(2.6343, grad_fn=<MseLossBackward>)\n",
      "Loss after:5 iterations is :tensor(11.3588, grad_fn=<MseLossBackward>)\n",
      "Loss after:6 iterations is :tensor(50.3216, grad_fn=<MseLossBackward>)\n",
      "Loss after:7 iterations is :tensor(10.8977, grad_fn=<MseLossBackward>)\n",
      "Loss after:8 iterations is :tensor(53.1362, grad_fn=<MseLossBackward>)\n",
      "Loss after:9 iterations is :tensor(44.9289, grad_fn=<MseLossBackward>)\n",
      "Loss after:10 iterations is :tensor(8.8292, grad_fn=<MseLossBackward>)\n",
      "Loss after:11 iterations is :tensor(9.8365, grad_fn=<MseLossBackward>)\n",
      "Loss after:12 iterations is :tensor(20.7486, grad_fn=<MseLossBackward>)\n",
      "Loss after:13 iterations is :tensor(7.6937, grad_fn=<MseLossBackward>)\n",
      "Loss after:14 iterations is :tensor(34.5452, grad_fn=<MseLossBackward>)\n",
      "Loss after:15 iterations is :tensor(8.1555, grad_fn=<MseLossBackward>)\n",
      "Loss after:16 iterations is :tensor(13.6196, grad_fn=<MseLossBackward>)\n",
      "Loss after:17 iterations is :tensor(60.2834, grad_fn=<MseLossBackward>)\n",
      "Loss after:18 iterations is :tensor(19.8280, grad_fn=<MseLossBackward>)\n",
      "Loss after:19 iterations is :tensor(118.5995, grad_fn=<MseLossBackward>)\n",
      "Loss after:20 iterations is :tensor(2.3423, grad_fn=<MseLossBackward>)\n",
      "Loss after:21 iterations is :tensor(18.5960, grad_fn=<MseLossBackward>)\n",
      "Loss after:22 iterations is :tensor(3.3208, grad_fn=<MseLossBackward>)\n",
      "Loss after:23 iterations is :tensor(107.2892, grad_fn=<MseLossBackward>)\n",
      "Loss after:24 iterations is :tensor(2.0878, grad_fn=<MseLossBackward>)\n",
      "Loss after:25 iterations is :tensor(51.2835, grad_fn=<MseLossBackward>)\n",
      "Loss after:26 iterations is :tensor(23.8260, grad_fn=<MseLossBackward>)\n",
      "Loss after:27 iterations is :tensor(84.4157, grad_fn=<MseLossBackward>)\n",
      "Loss after:28 iterations is :tensor(12.4015, grad_fn=<MseLossBackward>)\n",
      "Loss after:29 iterations is :tensor(7.8705, grad_fn=<MseLossBackward>)\n",
      "Loss after:30 iterations is :tensor(0.8893, grad_fn=<MseLossBackward>)\n",
      "Loss after:31 iterations is :tensor(30.7977, grad_fn=<MseLossBackward>)\n",
      "Loss after:32 iterations is :tensor(7.7485, grad_fn=<MseLossBackward>)\n",
      "Loss after:33 iterations is :tensor(1.3782, grad_fn=<MseLossBackward>)\n",
      "Loss after:34 iterations is :tensor(21.5300, grad_fn=<MseLossBackward>)\n",
      "Loss after:35 iterations is :tensor(26.4763, grad_fn=<MseLossBackward>)\n",
      "Loss after:36 iterations is :tensor(4.0728, grad_fn=<MseLossBackward>)\n",
      "Loss after:37 iterations is :tensor(22.9575, grad_fn=<MseLossBackward>)\n",
      "Loss after:38 iterations is :tensor(17.1177, grad_fn=<MseLossBackward>)\n",
      "Loss after:39 iterations is :tensor(14.1029, grad_fn=<MseLossBackward>)\n",
      "Loss after:40 iterations is :tensor(37.4317, grad_fn=<MseLossBackward>)\n",
      "Loss after:41 iterations is :tensor(7.6192, grad_fn=<MseLossBackward>)\n",
      "Loss after:42 iterations is :tensor(17.9050, grad_fn=<MseLossBackward>)\n",
      "Loss after:43 iterations is :tensor(34.0228, grad_fn=<MseLossBackward>)\n",
      "Loss after:44 iterations is :tensor(18.6395, grad_fn=<MseLossBackward>)\n",
      "Loss after:45 iterations is :tensor(18.7327, grad_fn=<MseLossBackward>)\n",
      "Loss after:46 iterations is :tensor(15.9814, grad_fn=<MseLossBackward>)\n",
      "Loss after:47 iterations is :tensor(19.0897, grad_fn=<MseLossBackward>)\n",
      "Loss after:48 iterations is :tensor(4.6062, grad_fn=<MseLossBackward>)\n",
      "Loss after:49 iterations is :tensor(21.7756, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50 # or whatever\n",
    "batch_size = 128 # or whatever\n",
    "losses=[]\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # x is our input\n",
    "    permutation = torch.randperm(x.size()[0])\n",
    "\n",
    "    for i in range(0,x.size()[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = x[indices], y_target[indices]\n",
    "\n",
    "        # in case you wanted a semi-full example\n",
    "        outputs = core.forward(batch_x)\n",
    "        loss = loss_fn(outputs,batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    print(\"Loss after:\"+str(epoch)+\" iterations is :\"+ str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training Loss for Predictron with 10-step return')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"No. of iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss for Predictron with \"+str(k)+\"-step return\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 21])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([4])\n",
      "torch.Size([32, 4])\n",
      "torch.Size([32])\n",
      "torch.Size([16, 32])\n",
      "torch.Size([16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2])\n",
      "torch.Size([32, 4])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32])\n",
      "torch.Size([4, 32])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for p in core.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = preprocessing(\"/home/abc/Berkeley/Prof_Ram/CMAPSSData/test_FD001.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = getXY(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13096, 21])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13096, 1])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = core.forward(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(352.1293, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(predict_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>reward</th>\n",
       "      <th>MC_Val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>-0.267320</td>\n",
       "      <td>1.345990</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.261692</td>\n",
       "      <td>-1.374941</td>\n",
       "      <td>-0.870977</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>0.972392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075544</td>\n",
       "      <td>-0.193640</td>\n",
       "      <td>-0.867422</td>\n",
       "      <td>-0.808153</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.347263</td>\n",
       "      <td>-0.582306</td>\n",
       "      <td>0.231303</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>0.822260</td>\n",
       "      <td>-0.354514</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>-0.301643</td>\n",
       "      <td>0.911237</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>-0.348639</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013802</td>\n",
       "      <td>0.333283</td>\n",
       "      <td>-1.182480</td>\n",
       "      <td>0.849935</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>-1.274039</td>\n",
       "      <td>-0.582306</td>\n",
       "      <td>-0.879011</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>-0.721311</td>\n",
       "      <td>1.345990</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.010010</td>\n",
       "      <td>0.329943</td>\n",
       "      <td>2.116325</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>-1.713704</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.639885</td>\n",
       "      <td>1.211488</td>\n",
       "      <td>-0.734921</td>\n",
       "      <td>-0.480672</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.968564</td>\n",
       "      <td>0.264669</td>\n",
       "      <td>-0.733981</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106</td>\n",
       "      <td>0.549865</td>\n",
       "      <td>1.345990</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.760570</td>\n",
       "      <td>1.285318</td>\n",
       "      <td>0.320655</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>-1.640314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236365</td>\n",
       "      <td>0.684565</td>\n",
       "      <td>-0.520956</td>\n",
       "      <td>1.294619</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.968564</td>\n",
       "      <td>-2.205674</td>\n",
       "      <td>-0.922996</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>98</td>\n",
       "      <td>-0.585114</td>\n",
       "      <td>-1.374816</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>-0.511569</td>\n",
       "      <td>0.367918</td>\n",
       "      <td>2.186597</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>-0.686236</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.336111</td>\n",
       "      <td>1.387129</td>\n",
       "      <td>-1.296332</td>\n",
       "      <td>0.356990</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.157913</td>\n",
       "      <td>-1.005793</td>\n",
       "      <td>0.902961</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>-0.267320</td>\n",
       "      <td>1.005889</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>-0.436738</td>\n",
       "      <td>0.555795</td>\n",
       "      <td>-1.016006</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>0.341233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986865</td>\n",
       "      <td>-1.071845</td>\n",
       "      <td>0.912017</td>\n",
       "      <td>-0.511696</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>-1.274039</td>\n",
       "      <td>0.476412</td>\n",
       "      <td>1.484271</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>134</td>\n",
       "      <td>0.595264</td>\n",
       "      <td>-0.354514</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.286636</td>\n",
       "      <td>-1.027168</td>\n",
       "      <td>0.924694</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>0.429301</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.299706</td>\n",
       "      <td>-0.193640</td>\n",
       "      <td>1.622615</td>\n",
       "      <td>0.832699</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.968564</td>\n",
       "      <td>-1.993930</td>\n",
       "      <td>-0.480772</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>121</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.325687</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.511131</td>\n",
       "      <td>2.280666</td>\n",
       "      <td>1.604985</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>-0.466064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.389052</td>\n",
       "      <td>0.333283</td>\n",
       "      <td>0.730442</td>\n",
       "      <td>-0.080800</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.157913</td>\n",
       "      <td>-0.935212</td>\n",
       "      <td>0.297875</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>97</td>\n",
       "      <td>2.138835</td>\n",
       "      <td>-0.014413</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>-1.185055</td>\n",
       "      <td>-0.613439</td>\n",
       "      <td>-1.010025</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>1.456770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129151</td>\n",
       "      <td>-0.896204</td>\n",
       "      <td>1.122056</td>\n",
       "      <td>-0.880543</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>-1.274039</td>\n",
       "      <td>0.405831</td>\n",
       "      <td>0.282421</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>198</td>\n",
       "      <td>0.595264</td>\n",
       "      <td>1.005889</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.184617</td>\n",
       "      <td>2.702390</td>\n",
       "      <td>3.028364</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>-1.875164</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.211028</td>\n",
       "      <td>-0.369281</td>\n",
       "      <td>7.429102</td>\n",
       "      <td>2.221907</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>2.779215</td>\n",
       "      <td>-1.358699</td>\n",
       "      <td>-1.786046</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time         2         3         5         6         7         8  \\\n",
       "machine                                                                     \n",
       "1          31 -0.267320  1.345990  0.999962  0.261692 -1.374941 -0.870977   \n",
       "2          49  0.822260 -0.354514  0.999962  0.186860 -0.301643  0.911237   \n",
       "3         126 -0.721311  1.345990  0.999962  1.010010  0.329943  2.116325   \n",
       "4         106  0.549865  1.345990  0.999962  0.760570  1.285318  0.320655   \n",
       "5          98 -0.585114 -1.374816  0.999962 -0.511569  0.367918  2.186597   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "96         97 -0.267320  1.005889  0.999962 -0.436738  0.555795 -1.016006   \n",
       "97        134  0.595264 -0.354514  0.999962  0.286636 -1.027168  0.924694   \n",
       "98        121  0.776860  0.325687  0.999962  0.511131  2.280666  1.604985   \n",
       "99         97  2.138835 -0.014413  0.999962 -1.185055 -0.613439 -1.010025   \n",
       "100       198  0.595264  1.005889  0.999962  1.184617  2.702390  3.028364   \n",
       "\n",
       "                9        10        11  ...        16        17        18  \\\n",
       "machine                                ...                                 \n",
       "1        0.999962  0.175653  0.972392  ...  0.075544 -0.193640 -0.867422   \n",
       "2        0.999962  0.175653 -0.348639  ... -0.013802  0.333283 -1.182480   \n",
       "3        0.999962  0.175653 -1.713704  ... -1.639885  1.211488 -0.734921   \n",
       "4        0.999962  0.175653 -1.640314  ...  0.236365  0.684565 -0.520956   \n",
       "5        0.999962  0.175653 -0.686236  ... -1.336111  1.387129 -1.296332   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "96       0.999962  0.175653  0.341233  ...  0.986865 -1.071845  0.912017   \n",
       "97       0.999962  0.175653  0.429301  ... -0.299706 -0.193640  1.622615   \n",
       "98       0.999962  0.175653 -0.466064  ... -0.389052  0.333283  0.730442   \n",
       "99       0.999962  0.175653  1.456770  ...  0.129151 -0.896204  1.122056   \n",
       "100      0.999962  0.175653 -1.875164  ... -1.211028 -0.369281  7.429102   \n",
       "\n",
       "               19        20        21        24        25  reward  MC_Val  \n",
       "machine                                                                    \n",
       "1       -0.808153  0.999962  0.347263 -0.582306  0.231303    -100  -100.0  \n",
       "2        0.849935  0.999962 -1.274039 -0.582306 -0.879011    -100  -100.0  \n",
       "3       -0.480672  0.999962  1.968564  0.264669 -0.733981    -100  -100.0  \n",
       "4        1.294619  0.999962  1.968564 -2.205674 -0.922996    -100  -100.0  \n",
       "5        0.356990  0.999962  1.157913 -1.005793  0.902961    -100  -100.0  \n",
       "...           ...       ...       ...       ...       ...     ...     ...  \n",
       "96      -0.511696  0.999962 -1.274039  0.476412  1.484271    -100  -100.0  \n",
       "97       0.832699  0.999962  1.968564 -1.993930 -0.480772    -100  -100.0  \n",
       "98      -0.080800  0.999962  1.157913 -0.935212  0.297875    -100  -100.0  \n",
       "99      -0.880543  0.999962 -1.274039  0.405831  0.282421    -100  -100.0  \n",
       "100      2.221907  0.999962  2.779215 -1.358699 -1.786046    -100  -100.0  \n",
       "\n",
       "[100 rows x 24 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.iloc[20:40, 2:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>reward</th>\n",
       "      <th>MC_Val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>-0.267320</td>\n",
       "      <td>1.345990</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.261692</td>\n",
       "      <td>-1.374941</td>\n",
       "      <td>-0.870977</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>0.972392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075544</td>\n",
       "      <td>-0.193640</td>\n",
       "      <td>-0.867422</td>\n",
       "      <td>-0.808153</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.347263</td>\n",
       "      <td>-0.582306</td>\n",
       "      <td>0.231303</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>0.822260</td>\n",
       "      <td>-0.354514</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>-0.301643</td>\n",
       "      <td>0.911237</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>-0.348639</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013802</td>\n",
       "      <td>0.333283</td>\n",
       "      <td>-1.182480</td>\n",
       "      <td>0.849935</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>-1.274039</td>\n",
       "      <td>-0.582306</td>\n",
       "      <td>-0.879011</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>-0.721311</td>\n",
       "      <td>1.345990</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.010010</td>\n",
       "      <td>0.329943</td>\n",
       "      <td>2.116325</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>-1.713704</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.639885</td>\n",
       "      <td>1.211488</td>\n",
       "      <td>-0.734921</td>\n",
       "      <td>-0.480672</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.968564</td>\n",
       "      <td>0.264669</td>\n",
       "      <td>-0.733981</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106</td>\n",
       "      <td>0.549865</td>\n",
       "      <td>1.345990</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.760570</td>\n",
       "      <td>1.285318</td>\n",
       "      <td>0.320655</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>-1.640314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236365</td>\n",
       "      <td>0.684565</td>\n",
       "      <td>-0.520956</td>\n",
       "      <td>1.294619</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.968564</td>\n",
       "      <td>-2.205674</td>\n",
       "      <td>-0.922996</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>98</td>\n",
       "      <td>-0.585114</td>\n",
       "      <td>-1.374816</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>-0.511569</td>\n",
       "      <td>0.367918</td>\n",
       "      <td>2.186597</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>-0.686236</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.336111</td>\n",
       "      <td>1.387129</td>\n",
       "      <td>-1.296332</td>\n",
       "      <td>0.356990</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.157913</td>\n",
       "      <td>-1.005793</td>\n",
       "      <td>0.902961</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>-0.267320</td>\n",
       "      <td>1.005889</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>-0.436738</td>\n",
       "      <td>0.555795</td>\n",
       "      <td>-1.016006</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>0.341233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986865</td>\n",
       "      <td>-1.071845</td>\n",
       "      <td>0.912017</td>\n",
       "      <td>-0.511696</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>-1.274039</td>\n",
       "      <td>0.476412</td>\n",
       "      <td>1.484271</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>134</td>\n",
       "      <td>0.595264</td>\n",
       "      <td>-0.354514</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.286636</td>\n",
       "      <td>-1.027168</td>\n",
       "      <td>0.924694</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>0.429301</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.299706</td>\n",
       "      <td>-0.193640</td>\n",
       "      <td>1.622615</td>\n",
       "      <td>0.832699</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.968564</td>\n",
       "      <td>-1.993930</td>\n",
       "      <td>-0.480772</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>121</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.325687</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.511131</td>\n",
       "      <td>2.280666</td>\n",
       "      <td>1.604985</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>-0.466064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.389052</td>\n",
       "      <td>0.333283</td>\n",
       "      <td>0.730442</td>\n",
       "      <td>-0.080800</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.157913</td>\n",
       "      <td>-0.935212</td>\n",
       "      <td>0.297875</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>97</td>\n",
       "      <td>2.138835</td>\n",
       "      <td>-0.014413</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>-1.185055</td>\n",
       "      <td>-0.613439</td>\n",
       "      <td>-1.010025</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>1.456770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129151</td>\n",
       "      <td>-0.896204</td>\n",
       "      <td>1.122056</td>\n",
       "      <td>-0.880543</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>-1.274039</td>\n",
       "      <td>0.405831</td>\n",
       "      <td>0.282421</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>198</td>\n",
       "      <td>0.595264</td>\n",
       "      <td>1.005889</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.184617</td>\n",
       "      <td>2.702390</td>\n",
       "      <td>3.028364</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>-1.875164</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.211028</td>\n",
       "      <td>-0.369281</td>\n",
       "      <td>7.429102</td>\n",
       "      <td>2.221907</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>2.779215</td>\n",
       "      <td>-1.358699</td>\n",
       "      <td>-1.786046</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time         2         3         5         6         7         8  \\\n",
       "machine                                                                     \n",
       "1          31 -0.267320  1.345990  0.999962  0.261692 -1.374941 -0.870977   \n",
       "2          49  0.822260 -0.354514  0.999962  0.186860 -0.301643  0.911237   \n",
       "3         126 -0.721311  1.345990  0.999962  1.010010  0.329943  2.116325   \n",
       "4         106  0.549865  1.345990  0.999962  0.760570  1.285318  0.320655   \n",
       "5          98 -0.585114 -1.374816  0.999962 -0.511569  0.367918  2.186597   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "96         97 -0.267320  1.005889  0.999962 -0.436738  0.555795 -1.016006   \n",
       "97        134  0.595264 -0.354514  0.999962  0.286636 -1.027168  0.924694   \n",
       "98        121  0.776860  0.325687  0.999962  0.511131  2.280666  1.604985   \n",
       "99         97  2.138835 -0.014413  0.999962 -1.185055 -0.613439 -1.010025   \n",
       "100       198  0.595264  1.005889  0.999962  1.184617  2.702390  3.028364   \n",
       "\n",
       "                9        10        11  ...        16        17        18  \\\n",
       "machine                                ...                                 \n",
       "1        0.999962  0.175653  0.972392  ...  0.075544 -0.193640 -0.867422   \n",
       "2        0.999962  0.175653 -0.348639  ... -0.013802  0.333283 -1.182480   \n",
       "3        0.999962  0.175653 -1.713704  ... -1.639885  1.211488 -0.734921   \n",
       "4        0.999962  0.175653 -1.640314  ...  0.236365  0.684565 -0.520956   \n",
       "5        0.999962  0.175653 -0.686236  ... -1.336111  1.387129 -1.296332   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "96       0.999962  0.175653  0.341233  ...  0.986865 -1.071845  0.912017   \n",
       "97       0.999962  0.175653  0.429301  ... -0.299706 -0.193640  1.622615   \n",
       "98       0.999962  0.175653 -0.466064  ... -0.389052  0.333283  0.730442   \n",
       "99       0.999962  0.175653  1.456770  ...  0.129151 -0.896204  1.122056   \n",
       "100      0.999962  0.175653 -1.875164  ... -1.211028 -0.369281  7.429102   \n",
       "\n",
       "               19        20        21        24        25  reward  MC_Val  \n",
       "machine                                                                    \n",
       "1       -0.808153  0.999962  0.347263 -0.582306  0.231303    -100  -100.0  \n",
       "2        0.849935  0.999962 -1.274039 -0.582306 -0.879011    -100  -100.0  \n",
       "3       -0.480672  0.999962  1.968564  0.264669 -0.733981    -100  -100.0  \n",
       "4        1.294619  0.999962  1.968564 -2.205674 -0.922996    -100  -100.0  \n",
       "5        0.356990  0.999962  1.157913 -1.005793  0.902961    -100  -100.0  \n",
       "...           ...       ...       ...       ...       ...     ...     ...  \n",
       "96      -0.511696  0.999962 -1.274039  0.476412  1.484271    -100  -100.0  \n",
       "97       0.832699  0.999962  1.968564 -1.993930 -0.480772    -100  -100.0  \n",
       "98      -0.080800  0.999962  1.157913 -0.935212  0.297875    -100  -100.0  \n",
       "99      -0.880543  0.999962 -1.274039  0.405831  0.282421    -100  -100.0  \n",
       "100      2.221907  0.999962  2.779215 -1.358699 -1.786046    -100  -100.0  \n",
       "\n",
       "[100 rows x 24 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby('machine').last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.1381e+01],\n",
       "        [-3.4868e+01],\n",
       "        [-3.8742e+01],\n",
       "        [-4.3047e+01],\n",
       "        [-4.7830e+01],\n",
       "        [-5.3144e+01],\n",
       "        [-5.9049e+01],\n",
       "        [-6.5610e+01],\n",
       "        [-7.2900e+01],\n",
       "        [-8.1000e+01],\n",
       "        [-9.0000e+01],\n",
       "        [-1.0000e+02],\n",
       "        [-8.1914e-12],\n",
       "        [-9.1015e-12],\n",
       "        [-1.0113e-11],\n",
       "        [-1.1236e-11],\n",
       "        [-1.2485e-11],\n",
       "        [-1.3872e-11],\n",
       "        [-1.5414e-11],\n",
       "        [-1.7126e-11]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target[180:200,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3191e+01],\n",
       "        [-3.7794e+01],\n",
       "        [-2.6134e+01],\n",
       "        [-8.0198e+01],\n",
       "        [-6.3151e+01],\n",
       "        [-4.3087e+01],\n",
       "        [-6.9333e+01],\n",
       "        [-5.0656e+01],\n",
       "        [-8.4726e+01],\n",
       "        [-8.6461e+01],\n",
       "        [-7.3645e+01],\n",
       "        [-8.3484e+01],\n",
       "        [-3.7174e-02],\n",
       "        [-1.4892e-01],\n",
       "        [-5.3861e-01],\n",
       "        [-1.5128e-01],\n",
       "        [-4.8330e-01],\n",
       "        [-6.8250e-02],\n",
       "        [-1.2240e-01],\n",
       "        [-1.2974e-01]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core.forward(x[180:200,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
