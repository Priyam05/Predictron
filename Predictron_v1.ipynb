{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distributions and Modules\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalization(df):\n",
    "    df.iloc[:,2:]= df.iloc[:,2:].apply(lambda x: ((x-x.mean()) / (x.std())))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(path):\n",
    "    df = pd.read_csv(path, header=None, delimiter=' ')\n",
    "    \n",
    "    #Normalize the data\n",
    "    df = Normalization(df)\n",
    "    \n",
    "    #Drop the columns which has all values as Nan\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    \n",
    "    #Get Rewards for each time step : 0 except last time step where reward is -100\n",
    "    df['Counter'] = df.index\n",
    "    lastRowIndex = df.groupby(0).last().Counter.tolist()\n",
    "    df['reward'] = df['Counter'].apply(lambda x : -100 if x in lastRowIndex else 0 )\n",
    "    df.drop(columns=['Counter'],inplace=True)\n",
    "    \n",
    "    #Rename columns\n",
    "    df.rename(columns={0: \"machine\", 1: \"time\"}, inplace=True)\n",
    "    \n",
    "    #Calculate Monte Carlo Value for each row\n",
    "    df1 = df.groupby('machine').last()[['time']].reset_index()\n",
    "    df = pd.merge(df, df1, on = 'machine', how = 'left').rename(columns ={'time_x':'time','time_y':'lastTimeStamp'})\n",
    "    df['MC_Val'] = (gamma ** (df['lastTimeStamp'] - df['time'] )) * (-100)\n",
    "    df = df.drop(columns='lastTimeStamp')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing(\"/home/abc/Berkeley/Prof_Ram/CMAPSSData/train_FD001.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have added the reward and Val column. We will be using the Val column for the Monte Carlo return gamma**(T-t)  X  -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets build the Neural network for the predictron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network for Observation - Hidden State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_OH(nn.Module):\n",
    "    def __init__(self, input_size, out_size):\n",
    "        super(NN_OH,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,64)\n",
    "        self.fc2 = nn.Linear(64,64)\n",
    "        self.fc3 = nn.Linear(64,out_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN_OH(\n",
      "  (fc1): Linear(in_features=24, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size  = 24\n",
    "out_size = 4\n",
    "net = NN_OH(input_size, out_size)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network for Hidden State - Reward & Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_reward_val(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NN_reward_val,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,32)\n",
    "        self.fc2 = nn.Linear(32,16)\n",
    "        self.fc3 = nn.Linear(16,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Neural Network which will take my current hidden state to the next hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_HH(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NN_HH,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,32)\n",
    "        self.fc2 = nn.Linear(32,32)\n",
    "        self.fc3 = nn.Linear(32,input_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have all the required neural networks for the predictron. Lets build the Predictron\n",
    "\n",
    "class Predictron(nn.Module):\n",
    "    def __init__(self, obs_size, hid_size):\n",
    "        super(Predictron,self).__init__()\n",
    "        \n",
    "        #Instantiate Neural Network for Observation-Hidden State\n",
    "        self.fc1 = NN_OH(obs_size, hid_size)\n",
    "        \n",
    "        #Instantiate Neural Network for Hidden State - Reward, Value\n",
    "        self.fc2 = NN_reward_val(hid_size)\n",
    "        \n",
    "        #Instantiate Neural Network for Hidden State - Next Hidden State\n",
    "        self.fc3 = NN_HH(hid_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Predictron core will output the value estimate for the current observation. We will input x (observation) \n",
    "        #and get value estimate. This implementation is for a k-step return which can be extended to TD(lambda) return\n",
    "        \n",
    "        #First step: Get the Hidden state for the current observation\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        #Now we keep track of rewards for the k-step return\n",
    "        k=10\n",
    "        gamma = 0.9 #Discount Factor\n",
    "        reward = self.fc2(x)[:,0].reshape(-1,1)\n",
    "        #print(reward.shape)\n",
    "        for i in range(k-1):\n",
    "            #Take the next step\n",
    "            x = self.fc3(x)\n",
    "            reward += gamma*(self.fc2(x)[:,0].reshape(-1,1))\n",
    "        \n",
    "        val_kth = self.fc2(x)[:,1].reshape(-1,1)\n",
    "        \n",
    "        return reward+val_kth\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(df.iloc[:, 2:-2].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20631, 21])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = torch.tensor(df.iloc[:,-1].values).float()\n",
    "y_target = y_target.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20631, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "core = Predictron(x.shape[1], 4)\n",
    "optimizer = optim.Adam(core.parameters(), lr = 1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0622,  0.0653, -0.0565,  ..., -0.0020,  0.1188, -0.0421],\n",
      "        [ 0.0970,  0.0525, -0.0403,  ...,  0.0590,  0.1086,  0.2023],\n",
      "        [ 0.0337,  0.0763, -0.0384,  ...,  0.0860, -0.0680,  0.0994],\n",
      "        ...,\n",
      "        [ 0.0535, -0.0983, -0.1750,  ..., -0.0259, -0.0709,  0.1269],\n",
      "        [ 0.0216,  0.0153, -0.1540,  ...,  0.0612, -0.0131, -0.1431],\n",
      "        [-0.0856, -0.0237,  0.1316,  ..., -0.1657, -0.1346,  0.1800]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0854,  0.0286, -0.1152,  0.1265,  0.0671,  0.1372,  0.1355,  0.2180,\n",
      "         0.0128, -0.0915, -0.1091, -0.1731,  0.0942,  0.1300, -0.0557,  0.2142,\n",
      "         0.2149,  0.0527,  0.1224,  0.0886, -0.1496,  0.2085,  0.1418, -0.1031,\n",
      "         0.0075,  0.0262,  0.0989,  0.1009, -0.1228, -0.0096, -0.0915,  0.0479,\n",
      "         0.0764,  0.1064,  0.2101, -0.1426,  0.1012,  0.0392, -0.0085, -0.1507,\n",
      "         0.0668, -0.1366, -0.0620,  0.1245,  0.1772, -0.1851, -0.0659,  0.1420,\n",
      "        -0.0155,  0.0261,  0.0064, -0.1233,  0.1775,  0.0828,  0.0019, -0.0733,\n",
      "         0.1277,  0.1845,  0.2119,  0.0638,  0.0529, -0.0703, -0.1672,  0.1025],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0029,  0.0186, -0.0268,  ..., -0.0224,  0.1151,  0.0155],\n",
      "        [ 0.1188, -0.0476,  0.1229,  ..., -0.0401, -0.0102,  0.0887],\n",
      "        [ 0.0088, -0.0737, -0.0703,  ...,  0.0560, -0.0884,  0.0463],\n",
      "        ...,\n",
      "        [ 0.0721, -0.0877,  0.1127,  ..., -0.0035, -0.0082, -0.1121],\n",
      "        [-0.0292, -0.0212, -0.1122,  ..., -0.0298,  0.0634,  0.0755],\n",
      "        [-0.0288,  0.1058, -0.0367,  ..., -0.0110, -0.0649,  0.0563]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-8.3845e-02, -1.2270e-01,  1.0753e-01, -7.0265e-02, -1.8178e-02,\n",
      "         2.3762e-02,  9.7590e-02,  5.1836e-02, -1.1656e-01,  9.8409e-02,\n",
      "        -7.6966e-02,  3.3175e-02,  1.0011e-01, -2.6605e-02, -6.8173e-02,\n",
      "        -1.1580e-01, -1.0567e-01,  3.7651e-02,  1.1970e-01, -1.0877e-01,\n",
      "         9.3966e-03, -7.9421e-02, -1.9646e-03, -1.1659e-01, -1.1768e-01,\n",
      "        -5.8489e-02,  9.1611e-02,  6.0544e-02,  1.4785e-02, -7.7305e-02,\n",
      "        -1.1360e-01, -2.5962e-02,  3.7604e-02,  9.2523e-02,  7.5878e-02,\n",
      "        -1.2326e-01, -1.8304e-02, -1.1362e-01,  4.4839e-02, -2.9906e-02,\n",
      "        -1.0298e-01, -2.0167e-02,  5.2478e-02, -7.5569e-02, -8.5499e-02,\n",
      "         4.8099e-02, -2.6271e-02, -3.6292e-02,  6.3678e-02,  1.2490e-01,\n",
      "        -1.5193e-02, -1.1860e-01, -9.9039e-02,  7.7533e-02, -2.4126e-02,\n",
      "        -4.1964e-03,  1.0314e-01,  1.8511e-02, -4.2051e-05,  9.7383e-03,\n",
      "         7.9405e-02, -1.0699e-01,  7.8001e-02, -1.8583e-02],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0287,  0.0724,  0.1220,  0.1145, -0.0417,  0.0709, -0.0292, -0.1220,\n",
      "          0.0788,  0.0908,  0.0062,  0.0161, -0.0310, -0.0969,  0.0482,  0.0899,\n",
      "          0.0741, -0.0387,  0.1157,  0.1189,  0.1010,  0.0776,  0.1132, -0.0886,\n",
      "         -0.0620, -0.0214, -0.0707, -0.0145,  0.1237, -0.1023, -0.0839, -0.0081,\n",
      "          0.0902, -0.0812,  0.0710,  0.0587, -0.0026, -0.0117, -0.0427,  0.1159,\n",
      "          0.0984,  0.1209, -0.0021,  0.0150, -0.0010,  0.0509,  0.0945, -0.1235,\n",
      "         -0.0792,  0.0358, -0.0744, -0.0905,  0.1088, -0.0753, -0.0959,  0.0434,\n",
      "          0.0554, -0.0474, -0.0548, -0.0312, -0.0327,  0.0751, -0.0834, -0.0164],\n",
      "        [ 0.0409,  0.0056, -0.0297,  0.0520, -0.0921, -0.0853,  0.0054,  0.0706,\n",
      "         -0.0414,  0.1008, -0.0806,  0.0887,  0.0918,  0.0123,  0.0044, -0.1091,\n",
      "          0.0275, -0.0263,  0.0472, -0.1020, -0.0639, -0.0293, -0.0569, -0.0963,\n",
      "          0.0856, -0.0777, -0.0959,  0.0166, -0.1235, -0.0525,  0.0383,  0.1240,\n",
      "         -0.1183, -0.0220,  0.1167, -0.0561, -0.0723, -0.0300, -0.0850,  0.0938,\n",
      "          0.0180,  0.0821, -0.0181, -0.0484,  0.0977, -0.0389, -0.1091, -0.0713,\n",
      "         -0.0286,  0.0985, -0.0794,  0.0050, -0.0120, -0.0902, -0.0557, -0.0669,\n",
      "         -0.0880,  0.0252,  0.1026,  0.1249,  0.1227, -0.0969, -0.0265,  0.0548],\n",
      "        [ 0.1208, -0.0880,  0.0974, -0.1168, -0.0686,  0.0380,  0.0050, -0.0120,\n",
      "          0.0190,  0.0871,  0.0561,  0.0578,  0.0729, -0.1096,  0.0726,  0.1148,\n",
      "         -0.0111,  0.0743,  0.1115, -0.0657, -0.0718,  0.0869,  0.0891, -0.1144,\n",
      "          0.0849,  0.0770, -0.0464, -0.1159,  0.1139, -0.1183,  0.0050, -0.0006,\n",
      "         -0.1029, -0.1037, -0.1184, -0.0715,  0.0219, -0.0254, -0.0401, -0.0165,\n",
      "          0.0852, -0.0822, -0.0934,  0.0531,  0.0929,  0.1019,  0.0332, -0.0657,\n",
      "         -0.1099, -0.0967, -0.0404, -0.1143,  0.0877,  0.0060, -0.1013,  0.0060,\n",
      "         -0.0338,  0.0591, -0.0242, -0.0578,  0.0692, -0.1017, -0.1208,  0.0956],\n",
      "        [ 0.0947,  0.1214, -0.0925, -0.0786,  0.0023, -0.0808,  0.0514,  0.0995,\n",
      "         -0.0677,  0.1077, -0.0479,  0.0384, -0.1242,  0.0155, -0.1056, -0.0754,\n",
      "          0.0048,  0.0820,  0.0395,  0.0586, -0.0242, -0.0412, -0.0687,  0.0198,\n",
      "          0.0207, -0.0349, -0.0772, -0.0863, -0.0507,  0.1026, -0.0321, -0.0194,\n",
      "          0.0717, -0.1045,  0.0365,  0.1250, -0.0910,  0.0937, -0.0899, -0.1014,\n",
      "          0.0623, -0.0411, -0.0808, -0.1087,  0.0515,  0.0971, -0.0649,  0.0588,\n",
      "         -0.1134, -0.0771, -0.0145, -0.0073,  0.0742,  0.0013,  0.0534, -0.0383,\n",
      "          0.0777,  0.0561,  0.1242, -0.0988, -0.0860,  0.0841, -0.0937, -0.0964]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0534, -0.1206, -0.0681, -0.1171], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3576, -0.3550,  0.2528, -0.2829],\n",
      "        [ 0.3556,  0.3421,  0.0685, -0.2457],\n",
      "        [ 0.0949,  0.1301,  0.0042, -0.0131],\n",
      "        [-0.0756, -0.2474, -0.0196,  0.4375],\n",
      "        [ 0.3010, -0.4033,  0.2359, -0.3749],\n",
      "        [-0.3807, -0.0129,  0.4930, -0.2955],\n",
      "        [ 0.0158, -0.1653, -0.3498, -0.3698],\n",
      "        [-0.3219,  0.4958, -0.4253, -0.3226],\n",
      "        [-0.3857, -0.4769, -0.1338, -0.0208],\n",
      "        [ 0.4165,  0.3882, -0.0082,  0.2899],\n",
      "        [-0.4704, -0.3524, -0.1653, -0.4355],\n",
      "        [-0.2815, -0.0865,  0.1472,  0.3951],\n",
      "        [ 0.1971, -0.3757,  0.0310,  0.3564],\n",
      "        [-0.4281, -0.2489, -0.2643,  0.4199],\n",
      "        [-0.0618, -0.3687, -0.3702,  0.3220],\n",
      "        [ 0.4277, -0.3157, -0.0897, -0.3360],\n",
      "        [ 0.0149,  0.0221, -0.1943, -0.3506],\n",
      "        [ 0.3591,  0.1338,  0.3155,  0.4944],\n",
      "        [-0.2979,  0.0527, -0.3863, -0.3381],\n",
      "        [ 0.2940,  0.1715,  0.0575,  0.2436],\n",
      "        [ 0.3153,  0.2293, -0.2005, -0.1984],\n",
      "        [ 0.0983, -0.3331,  0.4876,  0.4807],\n",
      "        [-0.1859, -0.2691, -0.1208,  0.2603],\n",
      "        [ 0.1904,  0.2626,  0.2706,  0.1355],\n",
      "        [-0.1950, -0.2439, -0.0982,  0.1456],\n",
      "        [-0.3265, -0.4837,  0.4830, -0.0284],\n",
      "        [ 0.2519, -0.3968, -0.1381, -0.2511],\n",
      "        [ 0.2557, -0.3200, -0.4827, -0.2381],\n",
      "        [-0.1085, -0.4078, -0.3523,  0.4365],\n",
      "        [ 0.4938,  0.1707, -0.2066,  0.3408],\n",
      "        [-0.0861, -0.3730, -0.0808, -0.2930],\n",
      "        [ 0.4380, -0.2943,  0.2989, -0.4040]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.4765, -0.3835, -0.0849,  0.1103, -0.3864,  0.0008, -0.4734,  0.2175,\n",
      "         0.0839, -0.1721,  0.0978,  0.3267,  0.1493, -0.3887, -0.4389, -0.3906,\n",
      "         0.4379, -0.3285,  0.3592, -0.2184, -0.3019,  0.2358,  0.2661, -0.2899,\n",
      "         0.2107,  0.1561, -0.3190,  0.2655,  0.2560, -0.0987,  0.1592, -0.0509],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1486,  0.1010,  0.1399,  0.1554, -0.1344,  0.1136, -0.1572,  0.0690,\n",
      "         -0.0301,  0.1614, -0.0588, -0.0537, -0.0214,  0.0137, -0.0363,  0.1636,\n",
      "          0.1568, -0.0465, -0.1403,  0.0603,  0.0002, -0.0987,  0.0112,  0.1074,\n",
      "         -0.0705, -0.0699, -0.1101,  0.0996, -0.0639, -0.1509,  0.0493,  0.1638],\n",
      "        [-0.0593,  0.1105, -0.1134, -0.1186, -0.0844,  0.0478, -0.1312, -0.1155,\n",
      "         -0.1512, -0.1629,  0.1243, -0.1575,  0.0732, -0.0777, -0.1140, -0.1378,\n",
      "         -0.0991, -0.1082, -0.0143,  0.1627,  0.0621,  0.1733,  0.1467,  0.1636,\n",
      "         -0.1619,  0.1167, -0.1694,  0.1287,  0.0135,  0.0205, -0.1474, -0.0484],\n",
      "        [ 0.0462,  0.1626, -0.1447,  0.0195, -0.0483,  0.0636,  0.1397, -0.0154,\n",
      "          0.0136, -0.1717, -0.0808,  0.1355,  0.0607, -0.1651, -0.1036,  0.0102,\n",
      "          0.0396,  0.0375, -0.0249,  0.1305,  0.0695, -0.1174, -0.1225,  0.0523,\n",
      "          0.1507,  0.1629, -0.1657, -0.0848, -0.0328,  0.1011,  0.1560, -0.1570],\n",
      "        [-0.1742,  0.0063, -0.1595, -0.1354,  0.0524,  0.1635,  0.1323, -0.0570,\n",
      "         -0.0383,  0.0285, -0.0075, -0.0900, -0.0424,  0.1078, -0.0572, -0.0322,\n",
      "          0.1602, -0.0882, -0.0119,  0.0881, -0.0122,  0.1048, -0.1246,  0.1203,\n",
      "          0.0874, -0.1303, -0.0156, -0.0378, -0.1428, -0.1737,  0.0258,  0.0203],\n",
      "        [-0.0696, -0.0750,  0.1100, -0.0914,  0.1342,  0.0351, -0.1514,  0.1506,\n",
      "         -0.0326,  0.0044,  0.0679,  0.0418,  0.1018,  0.0361, -0.0646, -0.0985,\n",
      "         -0.0150, -0.0136,  0.1323, -0.0382, -0.1721, -0.0233, -0.0038,  0.0919,\n",
      "         -0.1413,  0.1197,  0.0784, -0.1668,  0.0554,  0.1138,  0.0363,  0.0895],\n",
      "        [ 0.0132, -0.1388,  0.0244, -0.0488, -0.0805,  0.0851,  0.0429, -0.0189,\n",
      "         -0.0487,  0.0414,  0.1515, -0.1167, -0.1502,  0.1348, -0.0742,  0.1457,\n",
      "         -0.0964,  0.0851,  0.0346,  0.1661, -0.1130, -0.0914,  0.0678, -0.0022,\n",
      "         -0.0498,  0.0199, -0.1308, -0.0311, -0.1291, -0.0034, -0.0169,  0.0283],\n",
      "        [-0.1394, -0.1020, -0.1571,  0.1480,  0.1062,  0.1453,  0.0145,  0.1555,\n",
      "          0.1639,  0.1278, -0.0183, -0.0611,  0.1091,  0.0577,  0.1623,  0.1349,\n",
      "         -0.0877, -0.0681,  0.0511,  0.1181,  0.0370,  0.0931, -0.0691, -0.1272,\n",
      "          0.0290, -0.1440,  0.0015,  0.0906, -0.1712,  0.0314,  0.0766,  0.0587],\n",
      "        [-0.1449, -0.1044, -0.0060,  0.0847, -0.0635,  0.1312,  0.0082, -0.1448,\n",
      "         -0.1022,  0.1498, -0.0823, -0.0174,  0.1198, -0.0911,  0.0366, -0.0313,\n",
      "          0.0236,  0.1012,  0.1160, -0.0734, -0.1519, -0.1066,  0.0348, -0.1465,\n",
      "         -0.0775,  0.1690, -0.1562, -0.1307,  0.1031, -0.0008,  0.0969,  0.0981],\n",
      "        [-0.0921, -0.1318,  0.1545,  0.1496, -0.0554, -0.1396, -0.1742,  0.1189,\n",
      "         -0.0804,  0.0401, -0.0103,  0.1054, -0.0904,  0.0088,  0.0908,  0.1596,\n",
      "          0.0474, -0.0757, -0.1283, -0.0329, -0.0476,  0.0417, -0.0964,  0.0083,\n",
      "          0.1085, -0.0625, -0.1679,  0.0385, -0.1450,  0.0590,  0.0474,  0.0158],\n",
      "        [-0.1391,  0.0858,  0.1457, -0.0942,  0.1629, -0.1189, -0.0835,  0.1071,\n",
      "         -0.0722, -0.0860, -0.0565,  0.0864, -0.0894, -0.1557, -0.1227,  0.1489,\n",
      "         -0.0245,  0.0578, -0.0362, -0.0038,  0.1384,  0.0286,  0.0222,  0.1458,\n",
      "          0.1749,  0.0161,  0.0840, -0.1060,  0.1101,  0.0306, -0.1252,  0.0174],\n",
      "        [-0.0137, -0.0841,  0.0535, -0.0643, -0.0976, -0.0481,  0.1715,  0.0043,\n",
      "         -0.0814, -0.0604,  0.0535,  0.1642, -0.1407,  0.1760,  0.0855,  0.1307,\n",
      "          0.0460,  0.1372,  0.1668,  0.1390, -0.1731,  0.0315, -0.0957, -0.1046,\n",
      "          0.0719,  0.1480,  0.0887, -0.1630, -0.0251, -0.0336,  0.0296, -0.0169],\n",
      "        [-0.1387,  0.0435, -0.1385,  0.1364,  0.1052, -0.1537,  0.0322, -0.1342,\n",
      "         -0.0185,  0.0940,  0.1057, -0.1052,  0.0801, -0.1365, -0.0820, -0.1492,\n",
      "         -0.1738, -0.1041, -0.1321, -0.1727,  0.0223,  0.1753,  0.1698,  0.0923,\n",
      "          0.0798,  0.0749, -0.0377, -0.1088,  0.1547, -0.1231, -0.0367,  0.1369],\n",
      "        [-0.1296,  0.1703,  0.0670, -0.0603, -0.0382,  0.1178,  0.1748,  0.0855,\n",
      "         -0.0245, -0.0224,  0.1130,  0.0580, -0.0541, -0.0787, -0.1736,  0.0388,\n",
      "         -0.0110,  0.0325, -0.1082,  0.0327, -0.1608, -0.1306, -0.1623, -0.0563,\n",
      "         -0.0186,  0.1619,  0.0658, -0.0492,  0.1659,  0.1375, -0.0782, -0.0223],\n",
      "        [ 0.0245, -0.0377,  0.0519,  0.0932, -0.0507, -0.0499, -0.0334,  0.1106,\n",
      "         -0.0462,  0.0781,  0.0772, -0.1288,  0.1593,  0.0425,  0.0352, -0.0829,\n",
      "         -0.0231,  0.1197, -0.0242, -0.1368,  0.0170,  0.1260, -0.1656,  0.0131,\n",
      "         -0.0479,  0.1477, -0.0191,  0.0824, -0.0855, -0.0297,  0.1169, -0.0078],\n",
      "        [ 0.1516, -0.0949, -0.1753,  0.1021, -0.0519, -0.0491,  0.0215,  0.0127,\n",
      "         -0.0419, -0.0540,  0.0754, -0.0699,  0.1351,  0.1434, -0.0281,  0.1299,\n",
      "         -0.0571, -0.1599,  0.1567, -0.1187,  0.0966,  0.0167,  0.0975, -0.1048,\n",
      "         -0.0368,  0.1224,  0.0542, -0.0999,  0.0581, -0.1755, -0.0123, -0.0747],\n",
      "        [ 0.0273, -0.0864, -0.0028,  0.0344, -0.1360, -0.0514,  0.0773,  0.1455,\n",
      "         -0.1026, -0.0926,  0.1652,  0.0149,  0.0539, -0.1150, -0.1123,  0.0607,\n",
      "         -0.0712, -0.1150,  0.0103,  0.0815, -0.1163, -0.0473, -0.0957,  0.1624,\n",
      "          0.1668, -0.0356, -0.0166,  0.0839, -0.0167, -0.1252, -0.0923,  0.1288]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1259,  0.1687, -0.0248, -0.0566, -0.0485, -0.1607, -0.0060, -0.0982,\n",
      "         0.1656, -0.0737,  0.0157, -0.1601,  0.0172, -0.1137, -0.0366, -0.0712],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0094,  0.0127, -0.1819, -0.0841, -0.0827,  0.2216, -0.1691, -0.2371,\n",
      "         -0.2088, -0.2329, -0.1745,  0.1386, -0.0025, -0.1132,  0.0769, -0.2085],\n",
      "        [ 0.1167,  0.0779, -0.0187, -0.0510, -0.0829, -0.0391,  0.0238,  0.1094,\n",
      "         -0.1837, -0.1913,  0.2103,  0.0665, -0.0225, -0.1569, -0.0687, -0.1165]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0973, 0.1125], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2524,  0.0394,  0.3518, -0.2674],\n",
      "        [-0.2965, -0.2497, -0.1801,  0.0599],\n",
      "        [ 0.0210, -0.4584, -0.1566, -0.0896],\n",
      "        [ 0.1113,  0.4438,  0.4368,  0.3606],\n",
      "        [-0.4953, -0.1703,  0.4439, -0.4116],\n",
      "        [ 0.1195, -0.1108,  0.0278, -0.2239],\n",
      "        [-0.1112,  0.3601, -0.0124,  0.1196],\n",
      "        [ 0.0673, -0.3538,  0.4072, -0.0403],\n",
      "        [-0.4485,  0.3096,  0.4714,  0.4167],\n",
      "        [-0.4077, -0.0382,  0.3759, -0.4846],\n",
      "        [-0.0506,  0.1817, -0.2235,  0.3588],\n",
      "        [ 0.1123, -0.0865,  0.2046,  0.4851],\n",
      "        [ 0.3682,  0.1035, -0.1818,  0.2092],\n",
      "        [ 0.3813, -0.2835,  0.4338,  0.0760],\n",
      "        [ 0.3542,  0.1848,  0.4036,  0.3094],\n",
      "        [ 0.0650, -0.4173,  0.3960,  0.4560],\n",
      "        [-0.2856, -0.3537, -0.4501,  0.2145],\n",
      "        [-0.1883, -0.1693, -0.1741,  0.2633],\n",
      "        [-0.1328, -0.2775, -0.4008,  0.1567],\n",
      "        [-0.0148, -0.3061,  0.4827,  0.3900],\n",
      "        [-0.3607, -0.2443, -0.0879, -0.4907],\n",
      "        [-0.3045,  0.4952,  0.2907,  0.2955],\n",
      "        [ 0.0873,  0.2911, -0.4743, -0.4117],\n",
      "        [-0.4060, -0.4715,  0.4936, -0.1135],\n",
      "        [-0.4275, -0.4765,  0.3402, -0.4120],\n",
      "        [ 0.0239,  0.2285, -0.1991,  0.3031],\n",
      "        [ 0.2657, -0.0537,  0.2511,  0.3408],\n",
      "        [ 0.4046, -0.0873,  0.1327, -0.2487],\n",
      "        [ 0.1192, -0.2900,  0.3879, -0.3939],\n",
      "        [ 0.2397,  0.2850, -0.2935,  0.3644],\n",
      "        [-0.3574,  0.3649, -0.4886,  0.1019],\n",
      "        [ 0.1536, -0.2946,  0.4511, -0.1594]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1684, -0.0788, -0.2841, -0.1183, -0.2637,  0.0589, -0.4649,  0.1701,\n",
      "        -0.2428,  0.2930, -0.1114,  0.2861,  0.1062, -0.0923, -0.2905,  0.1802,\n",
      "         0.2953,  0.1782,  0.2695,  0.2369,  0.1546, -0.2622, -0.0095, -0.3686,\n",
      "         0.3272, -0.3655, -0.2024, -0.2890, -0.4243,  0.3999,  0.4762, -0.3173],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0791,  0.1116,  0.1019,  ..., -0.0802, -0.0536, -0.0765],\n",
      "        [-0.1583, -0.1093,  0.1376,  ..., -0.0194, -0.0553,  0.0013],\n",
      "        [-0.0296,  0.1661, -0.0247,  ...,  0.0972,  0.1586,  0.1685],\n",
      "        ...,\n",
      "        [ 0.0009, -0.0365,  0.0124,  ..., -0.1363,  0.1306, -0.0716],\n",
      "        [ 0.0769, -0.1080,  0.1095,  ..., -0.0250, -0.0641,  0.1077],\n",
      "        [ 0.0224, -0.0031, -0.0007,  ..., -0.0070,  0.0663,  0.0473]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0776,  0.1133, -0.1624, -0.1180,  0.0455,  0.0907, -0.0008,  0.0719,\n",
      "        -0.0472, -0.0852,  0.1611, -0.0975, -0.0463,  0.0201,  0.1672, -0.1375,\n",
      "        -0.1568,  0.0363, -0.1441, -0.0526, -0.1570,  0.1056, -0.0563,  0.0781,\n",
      "        -0.1365,  0.1329,  0.0766,  0.1252,  0.1603,  0.0667,  0.1357,  0.1115],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0808, -0.0505, -0.0845,  0.1196,  0.1405, -0.0669,  0.1755, -0.0152,\n",
      "          0.0469,  0.0541,  0.0029, -0.1580,  0.0643, -0.0463, -0.1733, -0.0415,\n",
      "         -0.1724, -0.1183,  0.0421,  0.0753,  0.0753,  0.0275, -0.0219,  0.0532,\n",
      "         -0.1170,  0.0266,  0.1184, -0.1013,  0.1407, -0.0948,  0.0656, -0.1145],\n",
      "        [ 0.1558,  0.0662,  0.1270, -0.0920, -0.1707, -0.1589, -0.0077, -0.0352,\n",
      "         -0.0400,  0.0083,  0.1757,  0.1568,  0.1294,  0.1424, -0.0973, -0.0524,\n",
      "          0.1295, -0.1523, -0.0313, -0.1615, -0.1363,  0.0364, -0.1098,  0.1420,\n",
      "          0.0505, -0.1761, -0.1051,  0.1246,  0.1283,  0.1520, -0.1683,  0.1114],\n",
      "        [ 0.0969,  0.1010, -0.0413,  0.0736,  0.1141,  0.0225,  0.0214, -0.0569,\n",
      "          0.1033,  0.1048,  0.0722,  0.0383, -0.1192, -0.0952, -0.0285,  0.1062,\n",
      "         -0.0694,  0.1508, -0.0081,  0.0989,  0.0789, -0.1556,  0.1417,  0.1089,\n",
      "          0.1584, -0.0476, -0.1320,  0.1536, -0.0250,  0.1681, -0.1494, -0.0882],\n",
      "        [ 0.1348, -0.1532,  0.0744,  0.0136,  0.1492, -0.0607,  0.0898,  0.0130,\n",
      "          0.0436,  0.0045,  0.0194,  0.0993,  0.0900, -0.0899, -0.0957, -0.0779,\n",
      "          0.1081,  0.0914,  0.1635,  0.1624, -0.1503,  0.1557, -0.1125, -0.1261,\n",
      "         -0.1639,  0.0535,  0.1271, -0.1560, -0.1265, -0.1007,  0.0875,  0.0551]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1426, 0.0753, 0.0955, 0.0214], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in core.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after:0 iterations is :tensor(29.6008, grad_fn=<MseLossBackward>)\n",
      "Loss after:1 iterations is :tensor(61.5052, grad_fn=<MseLossBackward>)\n",
      "Loss after:2 iterations is :tensor(20.6799, grad_fn=<MseLossBackward>)\n",
      "Loss after:3 iterations is :tensor(92.8271, grad_fn=<MseLossBackward>)\n",
      "Loss after:4 iterations is :tensor(4.4778, grad_fn=<MseLossBackward>)\n",
      "Loss after:5 iterations is :tensor(63.4296, grad_fn=<MseLossBackward>)\n",
      "Loss after:6 iterations is :tensor(40.2566, grad_fn=<MseLossBackward>)\n",
      "Loss after:7 iterations is :tensor(1.7224, grad_fn=<MseLossBackward>)\n",
      "Loss after:8 iterations is :tensor(5.7516, grad_fn=<MseLossBackward>)\n",
      "Loss after:9 iterations is :tensor(5.1931, grad_fn=<MseLossBackward>)\n",
      "Loss after:10 iterations is :tensor(5.6642, grad_fn=<MseLossBackward>)\n",
      "Loss after:11 iterations is :tensor(9.0096, grad_fn=<MseLossBackward>)\n",
      "Loss after:12 iterations is :tensor(95.5353, grad_fn=<MseLossBackward>)\n",
      "Loss after:13 iterations is :tensor(0.7449, grad_fn=<MseLossBackward>)\n",
      "Loss after:14 iterations is :tensor(35.4724, grad_fn=<MseLossBackward>)\n",
      "Loss after:15 iterations is :tensor(2.6847, grad_fn=<MseLossBackward>)\n",
      "Loss after:16 iterations is :tensor(7.9210, grad_fn=<MseLossBackward>)\n",
      "Loss after:17 iterations is :tensor(4.1066, grad_fn=<MseLossBackward>)\n",
      "Loss after:18 iterations is :tensor(3.2029, grad_fn=<MseLossBackward>)\n",
      "Loss after:19 iterations is :tensor(10.1617, grad_fn=<MseLossBackward>)\n",
      "Loss after:20 iterations is :tensor(13.2236, grad_fn=<MseLossBackward>)\n",
      "Loss after:21 iterations is :tensor(2.7248, grad_fn=<MseLossBackward>)\n",
      "Loss after:22 iterations is :tensor(57.6521, grad_fn=<MseLossBackward>)\n",
      "Loss after:23 iterations is :tensor(43.9694, grad_fn=<MseLossBackward>)\n",
      "Loss after:24 iterations is :tensor(67.8270, grad_fn=<MseLossBackward>)\n",
      "Loss after:25 iterations is :tensor(62.4258, grad_fn=<MseLossBackward>)\n",
      "Loss after:26 iterations is :tensor(13.0245, grad_fn=<MseLossBackward>)\n",
      "Loss after:27 iterations is :tensor(3.5252, grad_fn=<MseLossBackward>)\n",
      "Loss after:28 iterations is :tensor(16.8654, grad_fn=<MseLossBackward>)\n",
      "Loss after:29 iterations is :tensor(6.5316, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30 # or whatever\n",
    "batch_size = 128 # or whatever\n",
    "losses=[]\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # x is our input\n",
    "    permutation = torch.randperm(x.size()[0])\n",
    "\n",
    "    for i in range(0,x.size()[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = x[indices], y_target[indices]\n",
    "\n",
    "        # in case you wanted a semi-full example\n",
    "        outputs = core.forward(batch_x)\n",
    "        loss = loss_fn(outputs,batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    print(\"Loss after:\"+str(epoch)+\" iterations is :\"+ str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"No. of iterations\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0413,  0.0039, -0.1608,  ...,  0.0169,  0.0957, -0.0936],\n",
      "        [ 0.0313,  0.1269,  0.1784,  ...,  0.1326,  0.0120,  0.1751],\n",
      "        [ 0.0120,  0.0076, -0.1330,  ...,  0.1366, -0.1324,  0.0191],\n",
      "        ...,\n",
      "        [ 0.1292, -0.3407, -0.0050,  ..., -0.1420, -0.0594,  0.1954],\n",
      "        [ 0.0236, -0.0176, -0.2390,  ...,  0.0812, -0.0611, -0.2153],\n",
      "        [-0.0803, -0.0446,  0.0326,  ..., -0.1332, -0.1822,  0.1025]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0189,  0.2474, -0.2099,  0.0453,  0.2067,  0.0221, -0.0157,  0.0921,\n",
      "         0.2276, -0.0227, -0.2096, -0.2449,  0.0010,  0.0864,  0.1494,  0.0873,\n",
      "         0.1056, -0.0527, -0.0291, -0.0453, -0.2549,  0.1049,  0.2446, -0.1311,\n",
      "        -0.0981, -0.0759, -0.0673,  0.1196, -0.2289, -0.1428,  0.1698, -0.1120,\n",
      "        -0.0213,  0.2983,  0.2985,  0.0269, -0.0502,  0.1394, -0.1103, -0.2975,\n",
      "        -0.0466, -0.2213, -0.1534, -0.0296,  0.0388, -0.2979,  0.1631,  0.3024,\n",
      "        -0.1375, -0.0749, -0.1543,  0.0353,  0.3209,  0.2643, -0.0932, -0.2197,\n",
      "         0.2965,  0.1790,  0.2871, -0.0421,  0.2378,  0.0997, -0.2523,  0.0035],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0172, -0.0007, -0.0453,  ..., -0.0346,  0.1001, -0.0025],\n",
      "        [ 0.0942, -0.0597,  0.1004,  ..., -0.0544, -0.0176,  0.0671],\n",
      "        [ 0.0282,  0.1342, -0.1721,  ...,  0.3358, -0.1311,  0.0577],\n",
      "        ...,\n",
      "        [ 0.0562, -0.0987,  0.1007,  ..., -0.0035, -0.0188, -0.1266],\n",
      "        [ 0.0047, -0.2567,  0.0067,  ..., -0.2409,  0.1291,  0.1383],\n",
      "        [ 0.0013, -0.0774,  0.0766,  ..., -0.2116, -0.0104,  0.1148]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1000, -0.1454,  0.2216,  0.1218, -0.1424,  0.1055,  0.0115, -0.0109,\n",
      "         0.0369,  0.2351, -0.1244,  0.1985,  0.0294, -0.0956, -0.1902, -0.1439,\n",
      "         0.0487,  0.2120,  0.2566,  0.0406,  0.1387, -0.0849,  0.1680,  0.1531,\n",
      "        -0.1918, -0.0534,  0.0010, -0.0349, -0.0023, -0.1682, -0.1829, -0.0875,\n",
      "         0.1830,  0.0169,  0.0035,  0.0349, -0.1408,  0.0603,  0.0317, -0.0385,\n",
      "         0.0255,  0.1301, -0.0415, -0.0900, -0.1170,  0.2079,  0.0878, -0.1191,\n",
      "        -0.0190,  0.0600, -0.1161, -0.1951, -0.0023, -0.0492, -0.1142,  0.0774,\n",
      "         0.2760, -0.0725, -0.0619, -0.0445,  0.0070, -0.1229,  0.0017, -0.0985],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-6.1383e-02,  5.3282e-02,  1.8480e-01,  2.5023e-01, -1.6434e-01,\n",
      "          2.7476e-01, -1.1935e-01, -2.2509e-01,  5.5622e-01,  2.1583e-01,\n",
      "          3.3860e-02,  6.7223e-02, -1.3301e-01, -2.0020e-01, -4.9580e-02,\n",
      "          7.5733e-02,  1.6067e-01,  1.0267e-01,  2.0056e-01,  2.2658e-01,\n",
      "          1.6512e-01,  7.2175e-02,  2.6203e-01,  3.6029e-01, -1.5585e-01,\n",
      "          3.6884e-02, -1.7224e-01, -1.2996e-01,  1.0763e-01, -2.0510e-01,\n",
      "         -1.8095e-01, -9.8833e-02,  1.6958e-01, -1.7942e-01, -1.7151e-02,\n",
      "          1.7007e-01, -9.0583e-02,  1.1426e-01, -2.9783e-02,  1.1306e-01,\n",
      "          1.7515e-01,  1.4912e-01, -9.8534e-02,  8.7185e-03,  2.9002e-02,\n",
      "          1.7088e-01,  2.1574e-01, -2.2169e-01, -1.8890e-01, -5.7982e-02,\n",
      "         -1.8046e-01, -1.8737e-01,  1.5231e-01, -2.1367e-01, -1.9442e-01,\n",
      "          4.4059e-01,  2.0084e-01, -1.5056e-01, -1.5305e-01, -1.2145e-01,\n",
      "         -1.2768e-01,  6.1109e-02, -1.7572e-01, -1.0531e-01],\n",
      "        [ 6.8099e-02,  2.2397e-02,  3.7736e-02,  2.9249e-01, -1.9591e-01,\n",
      "         -4.3740e-01,  1.2060e-02,  6.7939e-02, -7.6689e-01,  3.1495e-01,\n",
      "         -8.0725e-02,  3.7202e-01,  7.1573e-02, -7.9801e-03, -3.3079e-02,\n",
      "         -9.5574e-02,  1.8667e-01,  2.6651e-01,  2.5551e-01,  8.6509e-02,\n",
      "          1.0145e-01, -2.3787e-02,  1.5033e-01, -4.4958e-01,  9.2177e-02,\n",
      "         -1.7106e-01, -1.2490e-01, -3.7395e-02, -1.1025e-01, -7.3513e-02,\n",
      "          3.6521e-02,  1.4667e-01,  5.4736e-02, -6.3334e-02,  1.1120e-01,\n",
      "          1.4608e-01, -2.0001e-01,  2.1359e-01, -7.1447e-02,  9.7984e-02,\n",
      "          1.7206e-01,  2.7927e-01, -1.7522e-02, -3.7209e-02,  6.6677e-02,\n",
      "          1.4831e-01,  2.9284e-02, -7.4310e-02, -7.6548e-02,  1.1563e-01,\n",
      "         -1.9531e-01, -3.7638e-02,  2.4084e-02, -1.3690e-01, -1.0829e-01,\n",
      "         -5.6958e-01,  2.2816e-01,  2.9092e-02,  1.1063e-01,  1.5864e-01,\n",
      "          7.4794e-02, -8.3361e-02, -3.6761e-02,  8.3422e-02],\n",
      "        [ 1.0167e-01, -7.9080e-02,  2.2681e-01,  4.6777e-02, -1.8036e-01,\n",
      "          2.0626e-01, -6.9379e-02, -9.7350e-02,  5.4527e-01,  2.5070e-01,\n",
      "          1.1253e-01,  1.1336e-01, -1.4865e-02, -1.9118e-01, -3.5757e-03,\n",
      "          1.2609e-01,  9.7252e-02,  2.4354e-01,  2.3543e-01,  7.2092e-02,\n",
      "          1.1055e-02,  9.2513e-02,  2.9003e-01, -5.9164e-02,  8.8950e-03,\n",
      "          1.3600e-01, -1.3526e-01, -2.1829e-01,  1.2454e-01, -2.0057e-01,\n",
      "         -7.5762e-02, -7.2503e-02,  4.0361e-04, -1.8066e-01, -1.9440e-01,\n",
      "          6.6730e-02, -4.5066e-02,  1.2528e-01, -2.8654e-02, -2.5032e-02,\n",
      "          2.0016e-01, -5.6438e-02, -1.7648e-01,  6.5184e-02,  1.2208e-01,\n",
      "          2.6673e-01,  1.7096e-01, -1.4394e-01, -2.1038e-01, -1.7051e-01,\n",
      "         -1.3118e-01, -1.9476e-01,  1.4018e-01, -1.3463e-01, -1.7701e-01,\n",
      "          3.9500e-01,  1.4099e-01, -2.9064e-02, -1.0367e-01, -1.3424e-01,\n",
      "         -9.0608e-03, -1.0145e-01, -1.9352e-01,  2.0939e-02],\n",
      "        [ 6.3627e-02,  1.0180e-01, -5.6541e-02,  8.3862e-02, -1.2222e-01,\n",
      "         -8.1745e-02, -2.2966e-02,  1.8587e-03,  3.7521e-01,  2.5400e-01,\n",
      "         -1.7965e-02,  1.4144e-01, -2.2382e-01, -8.2093e-02, -2.0240e-01,\n",
      "         -9.0421e-02,  1.1477e-01,  2.6556e-01,  1.4737e-01,  1.8295e-01,\n",
      "          4.4607e-02, -4.5868e-02,  9.5004e-02,  2.8243e-01, -6.5590e-02,\n",
      "          4.2844e-02, -1.7486e-01, -1.9765e-01, -7.0680e-02,  5.6438e-03,\n",
      "         -1.2482e-01, -1.0098e-01,  1.6371e-01, -2.0414e-01, -4.2085e-02,\n",
      "          2.4301e-01, -1.9416e-01,  2.6467e-01, -7.7063e-02, -1.0555e-01,\n",
      "          1.4093e-01,  8.2701e-03, -1.6872e-01, -1.1201e-01,  7.8634e-02,\n",
      "          2.2907e-01,  1.8166e-02, -3.2248e-02, -2.1793e-01, -1.6262e-01,\n",
      "         -1.3049e-01, -1.0180e-01,  6.7362e-02, -1.0341e-01, -4.5250e-02,\n",
      "          3.9982e-01,  2.8997e-01, -3.6240e-02,  3.3529e-02, -1.7481e-01,\n",
      "         -1.7808e-01,  7.0218e-02, -1.8370e-01, -1.7398e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1111,  0.0719,  0.0121, -0.0480], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2790, -0.4335,  0.1498, -0.1804],\n",
      "        [ 0.3688,  0.4625, -0.0685, -0.1847],\n",
      "        [ 0.1079,  0.2676, -0.0184,  0.0143],\n",
      "        [-0.0778, -0.2879,  0.0544,  0.4023],\n",
      "        [ 0.4444, -0.3245,  0.3215, -0.2420],\n",
      "        [-0.4765,  0.0185,  0.4500, -0.3415],\n",
      "        [-0.1070, -0.0568, -0.3674, -0.4862],\n",
      "        [-0.4131,  0.5805, -0.4723, -0.4118],\n",
      "        [-0.4501, -0.4448, -0.1870, -0.0639],\n",
      "        [ 0.4745,  0.1998, -0.0457,  0.4411],\n",
      "        [-0.5752, -0.2980, -0.2342, -0.5066],\n",
      "        [-0.3223, -0.0013,  0.1634,  0.3490],\n",
      "        [ 0.1830, -0.5164, -0.0060,  0.3798],\n",
      "        [-0.5720, -0.1724, -0.3995,  0.2811],\n",
      "        [-0.2398, -0.2696, -0.5389,  0.1480],\n",
      "        [ 0.4665, -0.6172, -0.0199, -0.3704],\n",
      "        [-0.0517,  0.0972, -0.2364, -0.4314],\n",
      "        [ 0.3718,  0.1830,  0.1843,  0.6048],\n",
      "        [-0.4025,  0.1138, -0.4158, -0.4087],\n",
      "        [ 0.1533,  0.4494, -0.0434,  0.1208],\n",
      "        [ 0.2240,  0.4083, -0.3487, -0.2608],\n",
      "        [ 0.0476, -0.4928,  0.4212,  0.4904],\n",
      "        [-0.1397, -0.3298, -0.1218,  0.3210],\n",
      "        [ 0.1141,  0.5783,  0.0780,  0.1220],\n",
      "        [-0.2741, -0.1808, -0.3189,  0.0861],\n",
      "        [-0.3663, -0.4257,  0.5537, -0.0897],\n",
      "        [ 0.2784, -0.4400, -0.1114, -0.2263],\n",
      "        [ 0.0667, -0.2509, -0.6699, -0.3708],\n",
      "        [-0.0966, -0.4864, -0.3543,  0.4692],\n",
      "        [ 0.4527,  0.0408, -0.2963,  0.3805],\n",
      "        [-0.1660, -0.2995, -0.0897, -0.3816],\n",
      "        [ 0.3942, -0.2681,  0.3268, -0.4303]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.4306, -0.2875, -0.0434,  0.1122, -0.2995, -0.0402, -0.4518,  0.2365,\n",
      "         0.0108, -0.3018,  0.0837,  0.3394,  0.0329, -0.4426, -0.4448, -0.1994,\n",
      "         0.4390, -0.3207,  0.3435, -0.1471, -0.1649,  0.0890,  0.2365, -0.0987,\n",
      "         0.1984,  0.1627, -0.2660,  0.2182,  0.2434, -0.2764,  0.1717, -0.0894],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.8396e-01,  2.7261e-01,  2.7041e-01, -1.1374e-01, -3.3793e-01,\n",
      "          1.7213e-01, -1.0954e-01,  1.0950e-01, -2.6415e-02,  1.4861e-01,\n",
      "         -1.2882e-02, -7.0098e-02, -2.7901e-01, -1.0427e-01, -1.5579e-01,\n",
      "          1.2327e-01,  1.6666e-01, -9.2407e-02, -1.1522e-01,  1.5172e-01,\n",
      "          1.6639e-01, -2.6241e-01, -4.7598e-02,  1.8649e-01, -1.7999e-01,\n",
      "         -1.7897e-02, -1.1007e-01, -5.9744e-02, -2.1785e-01, -2.2109e-01,\n",
      "          7.1505e-02,  2.1100e-01],\n",
      "        [-8.9055e-02,  7.0715e-02, -5.2257e-01, -1.6181e-01, -2.3349e-01,\n",
      "          2.0474e-02, -1.3118e-01, -1.4881e-01, -1.6332e-01, -2.5036e-01,\n",
      "          9.8024e-02, -1.9017e-01,  3.6889e-02, -7.7651e-02, -1.3433e-01,\n",
      "         -4.3999e-01, -1.3224e-01, -1.7512e-01, -4.5758e-02,  9.7405e-02,\n",
      "         -6.3851e-03,  1.4305e-01,  1.1214e-01,  1.2996e-01, -1.9816e-01,\n",
      "          9.0638e-02, -2.2132e-01,  8.8752e-02, -3.2558e-02, -1.0762e-01,\n",
      "         -1.7860e-01, -2.9977e-02],\n",
      "        [ 1.0873e-01,  3.4574e-01, -5.6061e-02,  9.8281e-03, -2.6330e-01,\n",
      "          1.5026e-01,  2.7980e-01,  8.5711e-02,  1.5432e-01, -2.2742e-01,\n",
      "          2.8814e-02,  1.5287e-01,  5.2736e-02,  3.7349e-02,  1.1682e-01,\n",
      "         -2.9900e-01,  1.0827e-01, -4.0614e-02,  7.1274e-02,  2.1939e-01,\n",
      "          3.2486e-01, -1.1035e-01, -8.7737e-02,  1.7538e-01,  2.5754e-01,\n",
      "          2.1796e-01, -1.2353e-01,  5.3600e-02, -2.0114e-03,  3.9591e-04,\n",
      "          2.3609e-01, -1.3350e-01],\n",
      "        [-1.2863e-01,  2.0186e-01,  9.7385e-03, -4.5017e-01, -1.7613e-01,\n",
      "          2.2583e-01,  2.6558e-01,  2.3564e-02,  7.3326e-02,  8.5299e-02,\n",
      "          7.6864e-02, -1.0543e-01, -3.3160e-01,  3.0938e-01,  1.6372e-01,\n",
      "         -8.9259e-02,  2.1172e-01, -1.1529e-01,  6.5741e-02,  2.0962e-01,\n",
      "          2.5794e-01, -4.9912e-02, -2.0349e-01,  2.7264e-01,  1.8884e-01,\n",
      "         -1.0758e-01,  1.3071e-02,  1.1003e-01, -1.3527e-01, -2.3281e-01,\n",
      "          8.8438e-02,  3.1120e-02],\n",
      "        [-1.3555e-02,  8.3453e-02,  1.0034e-01, -7.0658e-02,  9.4798e-02,\n",
      "          1.1350e-01, -1.4616e-02,  2.4457e-01,  1.0330e-01, -1.7810e-01,\n",
      "          1.7110e-01,  5.0699e-02,  1.6298e-01,  2.3789e-01,  1.5453e-01,\n",
      "         -6.4457e-01,  4.6766e-02, -2.0359e-01,  2.2199e-01,  1.3497e-02,\n",
      "          7.6840e-02,  2.5658e-02,  3.1153e-02,  1.1672e-01, -3.7421e-02,\n",
      "          1.6733e-01, -1.0424e-02, -2.2563e-02,  7.9821e-02, -1.1202e-01,\n",
      "          1.0999e-01,  1.2719e-01],\n",
      "        [-3.1150e-02, -1.5834e-01,  4.7471e-03, -4.8841e-02, -9.5528e-02,\n",
      "          3.9315e-02,  1.1330e-02, -5.4597e-02, -8.5461e-02,  2.1725e-02,\n",
      "          1.1279e-01, -1.5891e-01, -1.5024e-01,  1.0467e-01, -7.4198e-02,\n",
      "          1.4570e-01, -1.3342e-01,  6.5402e-02, -9.8872e-04,  1.4645e-01,\n",
      "         -1.3001e-01, -1.1108e-01,  6.1873e-02, -2.1830e-02, -8.4711e-02,\n",
      "         -5.3749e-03, -1.3076e-01, -6.0809e-02, -1.2907e-01, -2.3042e-02,\n",
      "         -5.8666e-02,  3.2842e-03],\n",
      "        [-7.7649e-02,  9.3074e-02, -1.5706e-01,  4.6414e-02,  1.0546e-01,\n",
      "          2.2955e-01,  1.5687e-01,  2.5598e-01,  3.0354e-01, -2.4996e-02,\n",
      "          9.0037e-02, -5.3432e-02,  5.0852e-02,  2.6192e-01,  3.8373e-01,\n",
      "         -2.1029e-01, -2.0109e-02, -2.3804e-01,  1.4777e-01,  2.2121e-01,\n",
      "          2.8128e-01,  9.4493e-02, -6.7758e-02, -8.1686e-02,  1.3747e-01,\n",
      "         -9.2180e-02,  1.6286e-03,  2.4993e-01, -2.0734e-01, -1.1826e-01,\n",
      "          1.5744e-01,  9.4248e-02],\n",
      "        [-1.1034e-01, -8.0475e-02, -5.4865e-02,  1.3997e-02, -5.3636e-02,\n",
      "          1.8133e-01,  1.0985e-01, -1.0526e-01, -4.7806e-02,  7.0811e-02,\n",
      "         -3.3851e-02, -2.9333e-02,  4.4701e-02, -9.1117e-02,  1.2286e-01,\n",
      "         -1.1178e-01,  4.1906e-02,  2.1487e-02,  1.4844e-01, -1.2678e-01,\n",
      "         -5.5557e-01, -1.9650e-01, -2.0208e-02, -2.9325e-01, -1.3818e-01,\n",
      "          2.0935e-01, -1.0681e-01, -4.8462e-01,  4.5075e-02, -7.8834e-02,\n",
      "          1.2813e-01,  1.2846e-01],\n",
      "        [-3.5821e-02,  3.7743e-02,  1.2513e-01,  1.9035e-01, -2.8653e-02,\n",
      "         -6.0563e-02, -3.8680e-02,  2.1288e-01,  5.4641e-02, -1.4329e-01,\n",
      "          9.2471e-02,  1.1941e-01, -1.5656e-02,  2.0914e-01,  3.0945e-01,\n",
      "         -1.3375e-02,  1.1008e-01, -2.6716e-01, -3.9201e-02,  2.9857e-02,\n",
      "          1.9452e-01,  1.0241e-01, -5.0921e-02,  1.6342e-03,  2.0965e-01,\n",
      "         -1.5557e-02, -2.2037e-01,  1.7389e-01, -1.0172e-01, -1.3309e-01,\n",
      "          1.1998e-01,  3.4065e-02],\n",
      "        [-3.9627e-01,  2.5486e-01,  4.8984e-01, -2.3928e-01, -2.6018e-01,\n",
      "         -9.6587e-02, -9.3713e-02,  2.4968e-01, -2.0843e-01, -5.6326e-02,\n",
      "         -5.1884e-02,  2.0538e-01, -2.7045e-01, -2.4837e-01, -3.0196e-01,\n",
      "          9.6969e-03,  5.7943e-02,  3.9682e-02,  5.3931e-02,  1.0691e-01,\n",
      "          4.1122e-01, -7.9138e-02, -2.0204e-01,  2.6019e-01,  1.3577e-01,\n",
      "         -2.1910e-01,  8.4029e-02, -1.6584e-01, -1.5567e-01,  6.8483e-04,\n",
      "         -2.3673e-01, -4.1856e-01],\n",
      "        [ 5.7300e-02,  8.9797e-02,  4.9474e-02, -4.8468e-02, -8.8982e-02,\n",
      "          4.7924e-02,  3.1718e-01,  1.1458e-01,  6.5800e-02, -2.3359e-01,\n",
      "          1.7176e-01,  1.8403e-01, -9.3951e-02,  3.7904e-01,  3.0627e-01,\n",
      "          1.7449e-02,  1.2296e-01, -3.8034e-02,  2.7231e-01,  2.2668e-01,\n",
      "          6.6488e-02,  7.5194e-02, -6.8375e-02, -7.3530e-02,  1.8382e-01,\n",
      "          2.1269e-01,  1.2533e-01, -2.2696e-02,  2.0280e-04, -1.8328e-01,\n",
      "          1.1947e-01,  2.0335e-02],\n",
      "        [-2.1677e-01,  2.5160e-02, -1.5757e-01,  4.6848e-02,  6.0958e-02,\n",
      "         -1.5367e-01,  3.2221e-02, -1.3420e-01, -1.8490e-02,  5.3613e-02,\n",
      "          1.0569e-01, -1.7420e-01,  1.1205e-02, -1.3647e-01, -1.6321e-01,\n",
      "         -1.8276e-01, -1.9885e-01, -1.4585e-01, -1.3212e-01, -1.9564e-01,\n",
      "          5.0726e-03,  1.1885e-01,  3.4622e-02,  6.2817e-02, -4.9912e-02,\n",
      "         -2.0415e-03, -7.8498e-02, -1.3968e-01,  1.3228e-02, -1.6865e-01,\n",
      "         -3.6664e-02,  1.0248e-01],\n",
      "        [-9.1117e-02,  3.5892e-01,  1.7503e-01, -3.8249e-01, -2.6075e-01,\n",
      "          1.8023e-01,  3.0825e-01,  1.6478e-01,  9.4527e-02, -4.1410e-02,\n",
      "          1.9952e-01,  4.0161e-02, -3.7324e-01,  1.1933e-01,  4.1031e-02,\n",
      "         -9.7202e-02,  3.2403e-02, -1.8377e-03, -3.3902e-02,  1.3244e-01,\n",
      "          9.4828e-02, -2.2932e-01, -2.2489e-01,  6.6515e-02,  7.2200e-02,\n",
      "          1.9005e-01,  9.6112e-02,  9.7489e-02,  6.8610e-02,  4.7697e-02,\n",
      "         -2.1250e-02, -8.3681e-03],\n",
      "        [ 6.6431e-02,  1.5870e-01,  7.3066e-02, -1.8925e-01, -3.2369e-02,\n",
      "          1.5924e-02,  1.0377e-01,  1.9311e-01,  7.7728e-02, -1.1459e-01,\n",
      "          1.6724e-01, -1.4430e-01,  1.0508e-02,  2.4622e-01,  2.5582e-01,\n",
      "         -2.0438e-01,  2.5058e-02, -9.3601e-02,  5.3976e-02, -3.0387e-02,\n",
      "          2.3983e-01,  3.7951e-02, -2.6553e-01,  4.3929e-02,  4.5266e-02,\n",
      "          1.7000e-01,  9.3162e-03,  2.3594e-01, -1.9929e-01, -2.4972e-01,\n",
      "          1.7820e-01,  1.2629e-02],\n",
      "        [ 1.1466e-01, -1.0190e-01, -1.7528e-01,  7.0154e-02, -3.8935e-02,\n",
      "         -1.0374e-01, -1.4868e-02, -4.0079e-02, -1.0017e-01, -6.0518e-02,\n",
      "          1.6376e-02, -1.0126e-01,  1.0488e-01,  1.0988e-01, -7.8087e-02,\n",
      "          1.1500e-01, -9.6905e-02, -1.6210e-01,  1.0798e-01, -1.1868e-01,\n",
      "          8.1963e-02, -1.2651e-02,  6.9928e-02, -1.6758e-01, -7.2545e-02,\n",
      "          8.3311e-02,  3.8294e-02, -1.2700e-01,  3.2209e-02, -2.2407e-01,\n",
      "         -5.7122e-02, -1.0747e-01],\n",
      "        [ 8.8771e-02,  6.1182e-02,  7.8853e-02, -1.6675e-02, -1.8721e-01,\n",
      "          3.0507e-02,  2.1713e-01,  2.4463e-01,  3.7829e-02, -1.2679e-01,\n",
      "          2.7305e-01,  2.7922e-02, -2.0163e-02,  8.8972e-02,  1.0919e-01,\n",
      "         -1.2156e-01, -3.6322e-03, -1.3152e-01,  1.0574e-01,  1.9822e-01,\n",
      "          1.3969e-01, -3.2557e-02, -6.4085e-02,  3.2621e-01,  2.7634e-01,\n",
      "          1.6613e-02,  1.6895e-02,  2.4220e-01, -1.9320e-02, -2.5464e-01,\n",
      "         -1.2812e-02,  1.6299e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1398,  0.1353,  0.0057, -0.0595, -0.0253, -0.1964,  0.0131, -0.1044,\n",
      "         0.1940,  0.0697,  0.0462, -0.2073,  0.0140, -0.1183, -0.0682, -0.0445],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0484, -0.0107, -0.2613, -0.1978, -0.1722,  0.1876, -0.2811, -0.2951,\n",
      "         -0.2642, -0.6441, -0.2648,  0.0891, -0.0865, -0.2145,  0.0419, -0.3141],\n",
      "        [ 0.1886,  0.0534,  0.0287, -0.0043, -0.0343, -0.0391,  0.0921,  0.1379,\n",
      "         -0.1379, -0.0334,  0.2580,  0.0665,  0.0341, -0.0966, -0.0892, -0.0495]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0674, 0.0825], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.3062, -0.0285,  0.2813, -0.1955],\n",
      "        [-0.2884, -0.3251, -0.1862,  0.0772],\n",
      "        [-0.0262, -0.4828, -0.1960, -0.1343],\n",
      "        [ 0.0845,  0.4815,  0.4793,  0.3119],\n",
      "        [-0.5299, -0.1558,  0.3504, -0.4344],\n",
      "        [ 0.1109, -0.1144, -0.0072, -0.2336],\n",
      "        [-0.1270,  0.3650, -0.0247,  0.1082],\n",
      "        [ 0.0844, -0.4046,  0.3525,  0.0142],\n",
      "        [-0.4680,  0.3314,  0.4435,  0.4058],\n",
      "        [-0.4405, -0.0006,  0.3341, -0.5270],\n",
      "        [-0.1221,  0.2314, -0.2848,  0.2931],\n",
      "        [ 0.0818, -0.0791,  0.1483,  0.4522],\n",
      "        [ 0.4826,  0.1342, -0.2355,  0.4146],\n",
      "        [ 0.3979, -0.4688,  0.3685,  0.1327],\n",
      "        [ 0.4207,  0.2026,  0.3154,  0.4785],\n",
      "        [ 0.0613, -0.4425,  0.3594,  0.4178],\n",
      "        [-0.3300, -0.3437, -0.4948,  0.1849],\n",
      "        [-0.2378, -0.1430, -0.2102,  0.2181],\n",
      "        [-0.1847, -0.2404, -0.4310,  0.1098],\n",
      "        [-0.0534, -0.3122,  0.4995,  0.3372],\n",
      "        [-0.3946, -0.2106, -0.1286, -0.5292],\n",
      "        [-0.3397,  0.5124,  0.1955,  0.2684],\n",
      "        [ 0.1367,  0.2264, -0.4884, -0.3474],\n",
      "        [-0.4458, -0.4645,  0.3681, -0.1355],\n",
      "        [-0.4505, -0.4533,  0.3184, -0.4422],\n",
      "        [ 0.0630,  0.4093, -0.1556,  0.3402],\n",
      "        [ 0.3264, -0.0912,  0.1814,  0.4836],\n",
      "        [ 0.4342, -0.2165,  0.0965, -0.2237],\n",
      "        [ 0.1211, -0.2971,  0.3811, -0.3874],\n",
      "        [ 0.2175,  0.3552, -0.3286,  0.3996],\n",
      "        [-0.3801,  0.3964, -0.5304,  0.0627],\n",
      "        [ 0.1558, -0.3010,  0.4454, -0.1546]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1717, -0.2820, -0.4259, -0.1547, -0.3599, -0.0454, -0.5542,  0.1179,\n",
      "        -0.3184,  0.2298, -0.1815,  0.2682,  0.1270, -0.2391, -0.3094,  0.1761,\n",
      "         0.1429,  0.0978,  0.2023,  0.2183,  0.0853, -0.3480, -0.1883, -0.4587,\n",
      "         0.2606, -0.2440, -0.2281, -0.3870, -0.5231,  0.3249,  0.3994, -0.4218],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0744,  0.0893,  0.0758,  ...,  0.0909, -0.0841, -0.0444],\n",
      "        [-0.1369, -0.0176,  0.2513,  ...,  0.0602, -0.0197,  0.0400],\n",
      "        [-0.0816,  0.2453,  0.0822,  ...,  0.2757,  0.2010,  0.1717],\n",
      "        ...,\n",
      "        [ 0.0171,  0.0526,  0.1225,  ..., -0.0665,  0.1634, -0.0343],\n",
      "        [ 0.0298, -0.1223,  0.1095,  ..., -0.0895, -0.0902,  0.0645],\n",
      "        [ 0.0294,  0.0851,  0.1067,  ...,  0.0290,  0.0907,  0.0792]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0655,  0.0600, -0.2498, -0.1663,  0.1294,  0.0294, -0.0232,  0.1145,\n",
      "        -0.1859, -0.1186,  0.0590, -0.1323, -0.0714, -0.0413,  0.1250, -0.1927,\n",
      "        -0.2452, -0.0194, -0.1866, -0.2198, -0.2305,  0.1849, -0.1116, -0.0019,\n",
      "        -0.2041,  0.1089,  0.0733,  0.0708,  0.2286,  0.0046,  0.0942,  0.0474],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0607, -0.0892, -0.1444,  0.0771,  0.2315, -0.0904,  0.1244,  0.1465,\n",
      "          0.0108,  0.0902, -0.0301, -0.1419,  0.0431, -0.0884, -0.1813, -0.0800,\n",
      "         -0.2065, -0.1565,  0.0022,  0.0133,  0.0274,  0.0888, -0.0667,  0.0202,\n",
      "         -0.1781,  0.0218,  0.1758, -0.1427,  0.1929, -0.1308,  0.0351, -0.1467],\n",
      "        [ 0.2361,  0.0577,  0.0952, -0.1110, -0.0921, -0.1675,  0.0076, -0.0038,\n",
      "         -0.0509,  0.0049,  0.1651,  0.1396,  0.1363,  0.1293, -0.1065, -0.0669,\n",
      "          0.1017, -0.1675, -0.0493, -0.1739, -0.1692,  0.0121, -0.1195,  0.1343,\n",
      "          0.0343, -0.1142, -0.0441,  0.1167,  0.1687,  0.1438, -0.1464,  0.1106],\n",
      "        [ 0.1518,  0.1009, -0.0421,  0.0646,  0.1091,  0.0110,  0.0831, -0.0278,\n",
      "          0.1037,  0.0897,  0.0665,  0.0544, -0.1202, -0.0937, -0.0514,  0.1029,\n",
      "         -0.0466,  0.1439, -0.0226,  0.1440,  0.0899, -0.2522,  0.1390,  0.1048,\n",
      "          0.1772, -0.0119, -0.1831,  0.1571, -0.0650,  0.1628, -0.1366, -0.0930],\n",
      "        [ 0.0705, -0.1967,  0.0067, -0.0286,  0.2079, -0.0895,  0.0366,  0.1251,\n",
      "          0.0046,  0.0408, -0.0187,  0.1138,  0.0741, -0.1351, -0.1105, -0.1252,\n",
      "          0.0688,  0.0449,  0.1248,  0.0773, -0.2041,  0.2014, -0.1653, -0.1641,\n",
      "         -0.2312,  0.0789,  0.1509, -0.2013, -0.0806, -0.1427,  0.0726,  0.0168]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1873, 0.0466, 0.0093, 0.0603], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in core.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.iloc[190:200,2:-2]\n",
    "sample = torch.tensor(sample.values).float()\n",
    "sample.shape\n",
    "\n",
    "predict = core.forward(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-59.4047],\n",
       "        [-68.6851],\n",
       "        [  0.1173],\n",
       "        [  0.1600],\n",
       "        [  0.1383],\n",
       "        [  0.1624],\n",
       "        [  0.1428],\n",
       "        [  0.1669],\n",
       "        [  0.1430],\n",
       "        [  0.1547]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.0000e+01],\n",
       "        [-1.0000e+02],\n",
       "        [-8.1914e-12],\n",
       "        [-9.1015e-12],\n",
       "        [-1.0113e-11],\n",
       "        [-1.1236e-11],\n",
       "        [-1.2485e-11],\n",
       "        [-1.3872e-11],\n",
       "        [-1.5414e-11],\n",
       "        [-1.7126e-11]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target[190:200,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
