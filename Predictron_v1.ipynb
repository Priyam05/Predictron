{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distributions and Modules\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalization(df):\n",
    "    df.iloc[:,2:]= df.iloc[:,2:].apply(lambda x: ((x-x.mean()) / (x.std())))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(path):\n",
    "    df = pd.read_csv(path, header=None, delimiter=' ')\n",
    "    \n",
    "    #Normalize the data\n",
    "    df = Normalization(df)\n",
    "    \n",
    "    #Drop the columns which has all values as Nan\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    \n",
    "    #Get Rewards for each time step : 0 except last time step where reward is -100\n",
    "    df['Counter'] = df.index\n",
    "    lastRowIndex = df.groupby(0).last().Counter.tolist()\n",
    "    df['reward'] = df['Counter'].apply(lambda x : -100 if x in lastRowIndex else 0 )\n",
    "    df.drop(columns=['Counter'],inplace=True)\n",
    "    \n",
    "    #Rename columns\n",
    "    df.rename(columns={0: \"machine\", 1: \"time\"}, inplace=True)\n",
    "    \n",
    "    #Calculate Monte Carlo Value for each row\n",
    "    df1 = df.groupby('machine').last()[['time']].reset_index()\n",
    "    df = pd.merge(df, df1, on = 'machine', how = 'left').rename(columns ={'time_x':'time','time_y':'lastTimeStamp'})\n",
    "    df['MC_Val'] = (gamma ** (df['lastTimeStamp'] - df['time'] )) * (-100)\n",
    "    df = df.drop(columns='lastTimeStamp')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing(\"/home/abc/Berkeley/Prof_Ram/CMAPSSData/train_FD001.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have added the reward and Val column. We will be using the Val column for the Monte Carlo return gamma**(T-t)  X  -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets build the Neural network for the predictron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network for Observation - Hidden State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_OH(nn.Module):\n",
    "    def __init__(self, input_size, out_size):\n",
    "        super(NN_OH,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,64)\n",
    "        self.fc2 = nn.Linear(64,64)\n",
    "        self.fc3 = nn.Linear(64,out_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN_OH(\n",
      "  (fc1): Linear(in_features=24, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size  = 24\n",
    "out_size = 4\n",
    "net = NN_OH(input_size, out_size)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network for Hidden State - Reward & Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_reward_val(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NN_reward_val,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,32)\n",
    "        self.fc2 = nn.Linear(32,16)\n",
    "        self.fc3 = nn.Linear(16,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Neural Network which will take my current hidden state to the next hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_HH(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NN_HH,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,32)\n",
    "        self.fc2 = nn.Linear(32,32)\n",
    "        self.fc3 = nn.Linear(32,input_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have all the required neural networks for the predictron. Lets build the Predictron\n",
    "\n",
    "class Predictron(nn.Module):\n",
    "    def __init__(self, obs_size, hid_size):\n",
    "        super(Predictron,self).__init__()\n",
    "        \n",
    "        #Instantiate Neural Network for Observation-Hidden State\n",
    "        self.fc1 = NN_OH(obs_size, hid_size)\n",
    "        \n",
    "        #Instantiate Neural Network for Hidden State - Reward, Value\n",
    "        self.fc2 = NN_reward_val(hid_size)\n",
    "        \n",
    "        #Instantiate Neural Network for Hidden State - Next Hidden State\n",
    "        self.fc3 = NN_HH(hid_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Predictron core will output the value estimate for the current observation. We will input x (observation) \n",
    "        #and get value estimate. This implementation is for a k-step return which can be extended to TD(lambda) return\n",
    "        \n",
    "        #First step: Get the Hidden state for the current observation\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        #Now we keep track of rewards for the k-step return\n",
    "        k=10\n",
    "        gamma = 0.9 #Discount Factor\n",
    "        reward = self.fc2(x)[:,0].reshape(-1,1)\n",
    "        #print(reward.shape)\n",
    "        for i in range(k-1):\n",
    "            #Take the next step\n",
    "            x = self.fc3(x)\n",
    "            reward += (gamma**(i+1))*(self.fc2(x)[:,0].reshape(-1,1))\n",
    "        \n",
    "        val_kth = (gamma**k)*self.fc2(self.fc3(x))[:,1].reshape(-1,1)\n",
    "        \n",
    "        return reward+val_kth\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(df.iloc[:, 2:-2].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20631, 21])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = torch.tensor(df.iloc[:,-1].values).float()\n",
    "y_target = y_target.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20631, 1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "core = Predictron(x.shape[1], 4)\n",
    "optimizer = optim.Adam(core.parameters(), lr = 1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0529, -0.0134,  0.0320,  ...,  0.0928, -0.0601, -0.0638],\n",
      "        [-0.0945, -0.2174,  0.1489,  ...,  0.1882, -0.1065,  0.1540],\n",
      "        [-0.0848,  0.0896, -0.0046,  ..., -0.1973, -0.0250,  0.0705],\n",
      "        ...,\n",
      "        [-0.2175,  0.0305,  0.0459,  ...,  0.0093, -0.1903, -0.0921],\n",
      "        [-0.0343, -0.1804, -0.1719,  ..., -0.0713,  0.2065, -0.1061],\n",
      "        [-0.1558, -0.1124,  0.1928,  ...,  0.1399,  0.1953, -0.0334]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0266,  0.1352,  0.0440,  0.1105, -0.0898, -0.0070, -0.1447,  0.1869,\n",
      "        -0.1259, -0.0770,  0.2137,  0.1404,  0.0502,  0.1938,  0.0266,  0.0807,\n",
      "        -0.0117,  0.0088, -0.1332,  0.1185, -0.1484,  0.1223, -0.0715, -0.0257,\n",
      "        -0.0677, -0.0277, -0.1884, -0.0921, -0.0570, -0.0977,  0.0804, -0.1446,\n",
      "        -0.0738,  0.0603, -0.1062,  0.0462, -0.0069,  0.0982, -0.0474, -0.1804,\n",
      "        -0.0150,  0.0770, -0.1904, -0.1325,  0.0468, -0.0154,  0.1298, -0.0058,\n",
      "         0.0418,  0.1454, -0.0467, -0.0543,  0.1644,  0.1189,  0.1825,  0.0195,\n",
      "        -0.0565,  0.1153,  0.1078,  0.0182, -0.0698, -0.1667, -0.1146,  0.1147],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0584,  0.1067, -0.1177,  ..., -0.0932,  0.0125, -0.0685],\n",
      "        [-0.0191, -0.0402,  0.0495,  ...,  0.1202, -0.0872, -0.0537],\n",
      "        [ 0.0131, -0.0663, -0.0790,  ..., -0.0080, -0.1165, -0.1182],\n",
      "        ...,\n",
      "        [ 0.0173, -0.0359, -0.0285,  ...,  0.0515, -0.0799,  0.0866],\n",
      "        [ 0.0429, -0.1214, -0.0848,  ..., -0.0249,  0.1070, -0.0550],\n",
      "        [-0.0531, -0.0352, -0.0865,  ...,  0.0833,  0.0803, -0.0977]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0758,  0.1092, -0.0562, -0.0620, -0.0753,  0.1056,  0.1126,  0.0604,\n",
      "         0.0677, -0.0543, -0.1170, -0.1049, -0.0714,  0.0414, -0.0694,  0.0657,\n",
      "        -0.0778,  0.0917, -0.1015,  0.0559,  0.1136, -0.0676,  0.0595, -0.0477,\n",
      "        -0.1002, -0.0639, -0.0287,  0.1071,  0.0009, -0.0063,  0.0501, -0.0768,\n",
      "         0.0148, -0.0686, -0.0458,  0.0052,  0.0903,  0.0162, -0.0277,  0.0355,\n",
      "         0.0615, -0.0530, -0.0425,  0.0495,  0.0057,  0.0819, -0.0964,  0.0101,\n",
      "         0.0167, -0.0196,  0.0118, -0.0241,  0.0116, -0.0276, -0.0282,  0.0090,\n",
      "        -0.0048, -0.0603, -0.0810, -0.0848, -0.0101, -0.0917, -0.0285, -0.0156],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0413, -0.0490, -0.1118, -0.0375,  0.1073, -0.0734, -0.1013,  0.0938,\n",
      "         -0.0354,  0.0661,  0.1165, -0.0078,  0.0207,  0.0784, -0.0494,  0.1019,\n",
      "         -0.0242,  0.1221,  0.0537,  0.1109, -0.0895, -0.0016,  0.0417,  0.1215,\n",
      "         -0.0072,  0.0033, -0.0947, -0.1200,  0.0687, -0.0272, -0.0804,  0.0231,\n",
      "         -0.0665, -0.1068,  0.0936, -0.1229,  0.0055,  0.1215, -0.0952,  0.0644,\n",
      "         -0.0429, -0.1029, -0.0433, -0.0390, -0.0532,  0.0366, -0.0161, -0.0945,\n",
      "         -0.0152,  0.0057, -0.0965,  0.0021,  0.0893,  0.0021, -0.0322,  0.0020,\n",
      "          0.0637, -0.0071,  0.0081, -0.0609, -0.1072,  0.1195,  0.0485, -0.0994],\n",
      "        [-0.0401,  0.0945,  0.0734,  0.0913, -0.0755,  0.1158,  0.0750,  0.0198,\n",
      "         -0.0794,  0.0673,  0.0198,  0.1140, -0.0470,  0.0378, -0.0824,  0.0040,\n",
      "          0.1220, -0.0550, -0.0259,  0.1142,  0.0855,  0.0003,  0.1057,  0.0278,\n",
      "         -0.0819, -0.0535, -0.0769, -0.0484,  0.0862, -0.0337, -0.0669,  0.0190,\n",
      "          0.0449,  0.0855,  0.0718,  0.0071, -0.0364, -0.0177, -0.0178, -0.0844,\n",
      "         -0.0269,  0.0712, -0.0524,  0.0636,  0.1093, -0.0681, -0.0070,  0.1083,\n",
      "          0.0638, -0.0982, -0.1246, -0.0435,  0.0314, -0.0992, -0.1142,  0.0979,\n",
      "         -0.0432,  0.0810,  0.1130,  0.0580, -0.0952,  0.0389,  0.0112,  0.0584],\n",
      "        [ 0.0956, -0.1119,  0.0165,  0.0585, -0.0034,  0.0469,  0.0989,  0.0626,\n",
      "         -0.0493,  0.0163,  0.1074, -0.0110,  0.0149,  0.0684, -0.0247,  0.0585,\n",
      "          0.0041,  0.0410, -0.1092,  0.0154, -0.0488, -0.1224,  0.0847,  0.1065,\n",
      "          0.0205,  0.0266, -0.1182,  0.0313, -0.1161,  0.0398, -0.0842,  0.0732,\n",
      "         -0.0725, -0.0408, -0.0398,  0.0306, -0.0068,  0.0716, -0.0881, -0.0317,\n",
      "          0.1058,  0.1214,  0.0203, -0.1221, -0.1034, -0.0074,  0.0899,  0.0904,\n",
      "         -0.0460, -0.0474, -0.0853, -0.1050, -0.1116,  0.0538,  0.0099,  0.0372,\n",
      "         -0.0678,  0.0185,  0.0259, -0.0995,  0.0406,  0.0736,  0.0376, -0.0568],\n",
      "        [-0.0954, -0.1192, -0.1150,  0.0334, -0.0184, -0.0643,  0.0340,  0.0388,\n",
      "         -0.0966,  0.1123, -0.0510,  0.0351,  0.1124, -0.0068, -0.0474, -0.0634,\n",
      "         -0.0008,  0.0341, -0.1035, -0.1231, -0.0030, -0.0013,  0.0102, -0.0275,\n",
      "         -0.0167, -0.0646, -0.0821, -0.0905,  0.0448,  0.0408, -0.0237, -0.0917,\n",
      "          0.0768,  0.0063,  0.1031,  0.0165,  0.0277, -0.0164, -0.0662, -0.0525,\n",
      "          0.0688,  0.1007, -0.0707,  0.0287,  0.0490, -0.0528, -0.1015, -0.0473,\n",
      "         -0.1067,  0.0540,  0.0897,  0.0108, -0.1212,  0.0157, -0.0999, -0.0996,\n",
      "         -0.0141, -0.0071,  0.0938, -0.0167, -0.0105, -0.0784,  0.1221,  0.0190]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0646,  0.0222,  0.0961,  0.0166], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3177,  0.2670, -0.1193, -0.0963],\n",
      "        [ 0.1229, -0.0299, -0.3923,  0.3742],\n",
      "        [-0.3591, -0.0885,  0.3255, -0.0585],\n",
      "        [ 0.0891,  0.3702, -0.4761,  0.2753],\n",
      "        [ 0.3680,  0.3928,  0.3611,  0.2815],\n",
      "        [ 0.0727, -0.1985,  0.1657,  0.0286],\n",
      "        [-0.0209, -0.4291, -0.0849,  0.4289],\n",
      "        [ 0.0274,  0.3209,  0.4318,  0.0506],\n",
      "        [-0.2031,  0.4702,  0.0845,  0.4892],\n",
      "        [ 0.1748,  0.1075,  0.1380,  0.3016],\n",
      "        [ 0.3757, -0.0341, -0.4739, -0.0521],\n",
      "        [ 0.3509, -0.3420,  0.4783, -0.4590],\n",
      "        [-0.3618,  0.3813, -0.2183,  0.3095],\n",
      "        [-0.2353, -0.0238,  0.2028,  0.0977],\n",
      "        [ 0.2222, -0.4273,  0.0929,  0.4283],\n",
      "        [-0.1736, -0.2252, -0.2477, -0.1857],\n",
      "        [-0.2897,  0.2930,  0.0720,  0.1957],\n",
      "        [ 0.3205,  0.3496, -0.0561,  0.3932],\n",
      "        [ 0.0546,  0.1849, -0.0847, -0.4706],\n",
      "        [-0.4706, -0.1287,  0.2517, -0.3076],\n",
      "        [-0.4696,  0.3161,  0.4653,  0.0961],\n",
      "        [ 0.4726, -0.0800, -0.3081,  0.1217],\n",
      "        [-0.1320, -0.0873, -0.4760,  0.1138],\n",
      "        [ 0.4933,  0.1506, -0.0551,  0.0095],\n",
      "        [ 0.0644,  0.2734, -0.3021, -0.1080],\n",
      "        [-0.2720, -0.1196, -0.0261,  0.3293],\n",
      "        [-0.2677, -0.2804,  0.4200,  0.1825],\n",
      "        [ 0.3672, -0.0053,  0.4182,  0.1601],\n",
      "        [-0.4237, -0.0276,  0.0415, -0.0923],\n",
      "        [ 0.3612,  0.0318,  0.2530,  0.3203],\n",
      "        [ 0.1371,  0.1494, -0.2339,  0.2303],\n",
      "        [ 0.0869, -0.4049, -0.3174,  0.3984]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.4476,  0.1029,  0.0569,  0.1409,  0.2276, -0.3254,  0.2352, -0.1428,\n",
      "        -0.4729, -0.2793, -0.1307, -0.2215, -0.4715, -0.2640,  0.4967, -0.0755,\n",
      "         0.3894,  0.3423, -0.4486, -0.2191, -0.4872, -0.4709, -0.4031,  0.0324,\n",
      "        -0.2160,  0.1458, -0.0428, -0.2354, -0.1054, -0.1326, -0.1062, -0.2141],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0989,  0.0411,  0.1359,  0.0469, -0.1624,  0.1081,  0.0338, -0.1591,\n",
      "          0.1729,  0.1172,  0.0392,  0.0879,  0.1188,  0.0560, -0.0250, -0.0176,\n",
      "          0.1047, -0.1590,  0.0412, -0.0160,  0.0287,  0.1027,  0.0926, -0.0921,\n",
      "          0.0786, -0.1639, -0.0341,  0.0841, -0.1218, -0.0191, -0.1356,  0.1126],\n",
      "        [-0.0289,  0.0228,  0.0703, -0.0462, -0.0463,  0.1161,  0.1024, -0.0751,\n",
      "         -0.0077,  0.1369, -0.0996, -0.1345, -0.1521,  0.1096, -0.0902,  0.0182,\n",
      "         -0.0140,  0.1150, -0.1391, -0.1621,  0.0518,  0.0603, -0.0672, -0.1486,\n",
      "         -0.0574, -0.1485,  0.1729, -0.0968, -0.1001,  0.1362, -0.0125, -0.0855],\n",
      "        [ 0.0949,  0.0166, -0.1182,  0.0969, -0.0515,  0.1221,  0.1575,  0.0890,\n",
      "          0.0545,  0.1216,  0.0109,  0.0711,  0.0635,  0.1030, -0.0350, -0.1241,\n",
      "          0.1151,  0.1615, -0.1186,  0.1093, -0.1141,  0.0152, -0.0491, -0.0226,\n",
      "         -0.0594, -0.1401, -0.0796, -0.0979, -0.1027,  0.1256,  0.0877, -0.1192],\n",
      "        [-0.0177,  0.1484, -0.1505, -0.1112,  0.0906,  0.0264, -0.0334,  0.1085,\n",
      "         -0.1566, -0.1653, -0.0566, -0.0793, -0.0819,  0.0666, -0.0166, -0.0028,\n",
      "          0.0314,  0.0730, -0.1208,  0.1399, -0.0701,  0.1656,  0.1400,  0.0904,\n",
      "         -0.1391, -0.1042,  0.1429,  0.1328, -0.0907, -0.1613, -0.1631, -0.0865],\n",
      "        [ 0.0055, -0.0770,  0.1656, -0.1149, -0.0478,  0.0474,  0.0612,  0.1656,\n",
      "          0.1674,  0.1146, -0.1541, -0.0628, -0.0757, -0.0245,  0.1350,  0.0478,\n",
      "          0.0387,  0.1345, -0.1624, -0.1393, -0.0208,  0.0430, -0.0433, -0.1010,\n",
      "          0.1595,  0.1063, -0.1288,  0.1381,  0.1464, -0.0857,  0.1501, -0.1157],\n",
      "        [-0.1023, -0.1012,  0.1734, -0.0071,  0.0601,  0.1597, -0.0297,  0.1074,\n",
      "         -0.1612, -0.1324,  0.0420, -0.1210, -0.0353, -0.0791, -0.1737,  0.0678,\n",
      "          0.1201,  0.1629, -0.0062,  0.1148, -0.1003, -0.1533,  0.1566, -0.0189,\n",
      "         -0.0546, -0.1094, -0.0751, -0.0048,  0.0008,  0.0141,  0.0861,  0.1453],\n",
      "        [ 0.1227,  0.1407, -0.0636, -0.1019,  0.0545, -0.1492, -0.0833,  0.0555,\n",
      "          0.0837, -0.1022, -0.1106, -0.1226,  0.1417, -0.0126,  0.0472, -0.1200,\n",
      "          0.1575, -0.0749, -0.1138,  0.1103, -0.0502,  0.1307, -0.0207,  0.1598,\n",
      "         -0.0495, -0.1715,  0.1176,  0.1159,  0.0795,  0.1704, -0.0456, -0.0093],\n",
      "        [-0.0906, -0.0476, -0.0315,  0.0853, -0.0618,  0.1039,  0.1336, -0.0586,\n",
      "          0.0285, -0.1075, -0.1296,  0.0919,  0.1381,  0.0048,  0.0489, -0.0195,\n",
      "         -0.1575, -0.0316, -0.0110, -0.1092, -0.0833,  0.0342, -0.0931, -0.0029,\n",
      "         -0.1259, -0.0330, -0.1603,  0.1583,  0.1097, -0.0218, -0.0174, -0.0729],\n",
      "        [ 0.1345,  0.1018, -0.0777,  0.1448,  0.1020, -0.0176, -0.0457,  0.1087,\n",
      "         -0.0651,  0.0738, -0.1128,  0.1040,  0.0687,  0.0029,  0.0860,  0.0810,\n",
      "         -0.0950,  0.0836,  0.0263,  0.1305, -0.1249,  0.1362, -0.0095, -0.0309,\n",
      "          0.0516, -0.1297, -0.0826, -0.1155, -0.0599,  0.1106, -0.0425,  0.1088],\n",
      "        [ 0.1178,  0.0842, -0.0871, -0.0268,  0.1202, -0.0327,  0.0672, -0.0150,\n",
      "          0.0315,  0.1643, -0.0949, -0.0167,  0.0513, -0.0963, -0.1213, -0.1209,\n",
      "         -0.0435,  0.1643,  0.1651,  0.1629, -0.1275, -0.0781, -0.0694,  0.0505,\n",
      "         -0.0179,  0.1557, -0.1513, -0.1598, -0.0267, -0.0466, -0.1051, -0.1574],\n",
      "        [ 0.1066,  0.0032,  0.0246,  0.1549,  0.0383,  0.1642, -0.1599,  0.1372,\n",
      "          0.1313,  0.0482, -0.0151, -0.1286, -0.1724,  0.0736,  0.0139, -0.1109,\n",
      "          0.1400, -0.0453, -0.0515, -0.0027,  0.1739,  0.1437, -0.0415, -0.1707,\n",
      "          0.1325, -0.0049, -0.0662,  0.0104,  0.0668,  0.1727,  0.1046, -0.0870],\n",
      "        [-0.1365,  0.1514, -0.1234, -0.1111, -0.0052,  0.1709,  0.0114, -0.0235,\n",
      "          0.0191,  0.0892, -0.0129,  0.0177,  0.0470,  0.0175,  0.1233,  0.0099,\n",
      "         -0.1121,  0.0389,  0.1200, -0.1648,  0.1300,  0.0466, -0.1344, -0.1127,\n",
      "          0.0454, -0.0937,  0.1217,  0.0608, -0.1431,  0.1253,  0.1176,  0.1349],\n",
      "        [-0.1334, -0.1615,  0.0363, -0.0836,  0.0202, -0.1376,  0.0351,  0.0195,\n",
      "         -0.1468,  0.0517, -0.1557,  0.0085,  0.0618, -0.0139,  0.0428,  0.1311,\n",
      "          0.0859, -0.1511, -0.1449, -0.0954, -0.0501,  0.1767, -0.0608, -0.0247,\n",
      "          0.1492,  0.0489,  0.0427,  0.0834, -0.1426,  0.1043, -0.1712,  0.1095],\n",
      "        [ 0.0858,  0.0435,  0.0818, -0.0621,  0.0581, -0.0494,  0.1524, -0.0234,\n",
      "          0.1687, -0.1123,  0.0715, -0.1108,  0.0283,  0.1075, -0.0615,  0.1183,\n",
      "         -0.0989, -0.1685,  0.0325,  0.0028,  0.0769,  0.0816, -0.1102,  0.0851,\n",
      "         -0.1583,  0.0369,  0.0535, -0.0300, -0.1638,  0.0053, -0.1287,  0.0017],\n",
      "        [-0.1213,  0.1317, -0.1294,  0.1710, -0.1321,  0.1683, -0.0723, -0.1434,\n",
      "         -0.0073,  0.1449, -0.0208,  0.0903, -0.1295,  0.1454, -0.1691, -0.0386,\n",
      "          0.0795, -0.1193, -0.0375, -0.0584,  0.0518, -0.0788,  0.1665, -0.0463,\n",
      "          0.0413, -0.1377,  0.0778, -0.1740,  0.1731, -0.1387, -0.0792,  0.0467],\n",
      "        [-0.0154, -0.1626,  0.0858, -0.0103,  0.1313,  0.1181, -0.1373,  0.1063,\n",
      "          0.1243, -0.0715, -0.0558, -0.0884,  0.0783,  0.1690, -0.1744,  0.1429,\n",
      "         -0.1029, -0.1622, -0.0860,  0.0595, -0.0901,  0.0391, -0.1384,  0.1159,\n",
      "         -0.1671,  0.0170,  0.0068, -0.0324, -0.0481,  0.1677, -0.1286, -0.0380]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1738,  0.0563,  0.0281, -0.0739,  0.1051, -0.0634,  0.1573, -0.0422,\n",
      "        -0.1565, -0.0806, -0.1422, -0.0860,  0.0744,  0.0758,  0.1007,  0.0076],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1746, -0.0576,  0.1366, -0.1914,  0.0803, -0.0991, -0.1673, -0.0149,\n",
      "          0.1503,  0.0761, -0.2102,  0.1123, -0.1302, -0.1802, -0.0998,  0.2382],\n",
      "        [-0.1394, -0.0723,  0.1632,  0.1636, -0.2365, -0.1616, -0.2436, -0.0150,\n",
      "         -0.2349,  0.0254,  0.0538,  0.1077,  0.2055, -0.1427, -0.2254,  0.2168]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2187,  0.0243], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4204, -0.0097, -0.0741,  0.4677],\n",
      "        [ 0.1207, -0.0714, -0.1702,  0.0297],\n",
      "        [ 0.1872,  0.4381, -0.4578, -0.2887],\n",
      "        [-0.4320,  0.0654,  0.2102,  0.0052],\n",
      "        [-0.3529,  0.4322,  0.2392,  0.1935],\n",
      "        [-0.3217, -0.0414,  0.3031, -0.2355],\n",
      "        [-0.0292,  0.1790,  0.2960,  0.3394],\n",
      "        [-0.3040, -0.0167,  0.2155, -0.2292],\n",
      "        [ 0.1094,  0.2696, -0.3910,  0.3742],\n",
      "        [-0.1812, -0.4101, -0.1135, -0.4557],\n",
      "        [-0.2821, -0.0241, -0.4313,  0.2050],\n",
      "        [ 0.2875,  0.2797, -0.1985,  0.4629],\n",
      "        [ 0.2736,  0.1821,  0.3948, -0.1515],\n",
      "        [ 0.4760, -0.4556, -0.1064,  0.4703],\n",
      "        [-0.4495, -0.2241, -0.3435, -0.1516],\n",
      "        [-0.0160,  0.3717,  0.1789, -0.0634],\n",
      "        [-0.2174,  0.0189,  0.0620,  0.0768],\n",
      "        [-0.3197, -0.2052, -0.2623,  0.3272],\n",
      "        [ 0.2670, -0.4960, -0.0542, -0.4690],\n",
      "        [ 0.0538, -0.1707,  0.4974, -0.2114],\n",
      "        [ 0.0351, -0.3727,  0.3882, -0.4519],\n",
      "        [ 0.0323, -0.1955,  0.4673,  0.3531],\n",
      "        [ 0.4326, -0.0887,  0.0513, -0.4985],\n",
      "        [-0.2481, -0.0297, -0.2888,  0.0316],\n",
      "        [ 0.0204,  0.0789, -0.2284, -0.3981],\n",
      "        [ 0.0733,  0.4207, -0.2975,  0.3484],\n",
      "        [-0.3368,  0.4715,  0.0387, -0.1046],\n",
      "        [-0.1555,  0.1779, -0.2982, -0.2997],\n",
      "        [ 0.3372,  0.3777, -0.0767,  0.3593],\n",
      "        [-0.3069,  0.3787,  0.4821,  0.0865],\n",
      "        [-0.3749, -0.3785, -0.0111, -0.0251],\n",
      "        [ 0.4424,  0.1375, -0.0160, -0.4812]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2151,  0.2341, -0.1058, -0.3150,  0.3614, -0.2926,  0.3143, -0.3117,\n",
      "        -0.3366, -0.4699,  0.2158,  0.0196, -0.1909, -0.2885,  0.2079, -0.1970,\n",
      "        -0.0531,  0.3717, -0.0440,  0.3455,  0.0459, -0.4172,  0.0651, -0.3961,\n",
      "         0.4684,  0.1193, -0.3170, -0.3854,  0.2218, -0.0460, -0.3644, -0.4035],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1338, -0.1041, -0.0980,  ..., -0.0716, -0.1458,  0.0217],\n",
      "        [ 0.1586,  0.0445, -0.1377,  ...,  0.1700, -0.1365, -0.1099],\n",
      "        [-0.0216, -0.1391, -0.0059,  ...,  0.0954, -0.0067, -0.1684],\n",
      "        ...,\n",
      "        [-0.1051,  0.1159, -0.0680,  ...,  0.1264, -0.0527,  0.0920],\n",
      "        [-0.0019,  0.1412,  0.0563,  ..., -0.0503, -0.1024, -0.1145],\n",
      "        [-0.0260,  0.0202,  0.1389,  ...,  0.1376,  0.1496,  0.0487]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0253,  0.0168,  0.0202,  0.0505,  0.0861, -0.1668,  0.0152, -0.1248,\n",
      "         0.0610, -0.1707,  0.0107, -0.1549, -0.0958,  0.0101, -0.1299, -0.0606,\n",
      "        -0.1733,  0.0385, -0.0936, -0.0054, -0.1600,  0.0474, -0.1287,  0.1455,\n",
      "        -0.0786, -0.1127,  0.1306, -0.0815,  0.1581, -0.1154,  0.0989, -0.0889],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0328, -0.0750,  0.1221,  0.0605,  0.0830, -0.1652, -0.0212,  0.0043,\n",
      "         -0.0520,  0.0770, -0.1654,  0.1162, -0.0646, -0.1468,  0.1455, -0.1390,\n",
      "          0.0607, -0.0045,  0.0247,  0.1075,  0.1327,  0.0854,  0.0548,  0.1295,\n",
      "          0.0784, -0.1719, -0.0415,  0.0259, -0.0735,  0.1697, -0.1496, -0.1182],\n",
      "        [-0.1743,  0.0317, -0.0564, -0.0643, -0.1321,  0.0998, -0.1017, -0.0291,\n",
      "         -0.0153, -0.1697, -0.1060,  0.1045,  0.0983, -0.1115, -0.0286, -0.0305,\n",
      "          0.1603,  0.1576, -0.0807,  0.1148,  0.0264,  0.0078,  0.1291,  0.1697,\n",
      "         -0.1284, -0.1510,  0.0740, -0.1250,  0.1766,  0.0053, -0.0925, -0.0633],\n",
      "        [ 0.0134, -0.0557, -0.1595,  0.0705, -0.1607, -0.1670,  0.1579, -0.1660,\n",
      "         -0.0770,  0.1765, -0.0401, -0.0896, -0.0256, -0.1617, -0.0301,  0.0719,\n",
      "          0.1348, -0.1248, -0.0536,  0.1412, -0.0033, -0.0315,  0.1301, -0.0685,\n",
      "          0.0078,  0.0500, -0.0942,  0.0788,  0.0988,  0.0410, -0.0991,  0.1096],\n",
      "        [-0.0400,  0.0927,  0.0319, -0.0093,  0.0786, -0.1656, -0.0303, -0.0662,\n",
      "          0.0229, -0.0957, -0.1521, -0.0797,  0.1437,  0.1739,  0.1272, -0.0213,\n",
      "          0.0761, -0.1138, -0.0430, -0.1100,  0.0687,  0.0701, -0.0512, -0.0677,\n",
      "          0.0429,  0.0731, -0.0294,  0.0584, -0.1269, -0.0790, -0.1076, -0.0291]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0212, -0.0104, -0.1384, -0.0638], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in core.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after:0 iterations is :tensor(12.6439, grad_fn=<MseLossBackward>)\n",
      "Loss after:1 iterations is :tensor(11.5024, grad_fn=<MseLossBackward>)\n",
      "Loss after:2 iterations is :tensor(12.6352, grad_fn=<MseLossBackward>)\n",
      "Loss after:3 iterations is :tensor(1.0436, grad_fn=<MseLossBackward>)\n",
      "Loss after:4 iterations is :tensor(3.1699, grad_fn=<MseLossBackward>)\n",
      "Loss after:5 iterations is :tensor(5.4155, grad_fn=<MseLossBackward>)\n",
      "Loss after:6 iterations is :tensor(14.8636, grad_fn=<MseLossBackward>)\n",
      "Loss after:7 iterations is :tensor(25.5870, grad_fn=<MseLossBackward>)\n",
      "Loss after:8 iterations is :tensor(46.7553, grad_fn=<MseLossBackward>)\n",
      "Loss after:9 iterations is :tensor(44.2542, grad_fn=<MseLossBackward>)\n",
      "Loss after:10 iterations is :tensor(15.5817, grad_fn=<MseLossBackward>)\n",
      "Loss after:11 iterations is :tensor(8.3600, grad_fn=<MseLossBackward>)\n",
      "Loss after:12 iterations is :tensor(0.1483, grad_fn=<MseLossBackward>)\n",
      "Loss after:13 iterations is :tensor(41.9243, grad_fn=<MseLossBackward>)\n",
      "Loss after:14 iterations is :tensor(0.8623, grad_fn=<MseLossBackward>)\n",
      "Loss after:15 iterations is :tensor(99.9618, grad_fn=<MseLossBackward>)\n",
      "Loss after:16 iterations is :tensor(30.0224, grad_fn=<MseLossBackward>)\n",
      "Loss after:17 iterations is :tensor(7.0285, grad_fn=<MseLossBackward>)\n",
      "Loss after:18 iterations is :tensor(30.4666, grad_fn=<MseLossBackward>)\n",
      "Loss after:19 iterations is :tensor(7.7929, grad_fn=<MseLossBackward>)\n",
      "Loss after:20 iterations is :tensor(17.4721, grad_fn=<MseLossBackward>)\n",
      "Loss after:21 iterations is :tensor(35.7679, grad_fn=<MseLossBackward>)\n",
      "Loss after:22 iterations is :tensor(19.1181, grad_fn=<MseLossBackward>)\n",
      "Loss after:23 iterations is :tensor(16.9413, grad_fn=<MseLossBackward>)\n",
      "Loss after:24 iterations is :tensor(37.0251, grad_fn=<MseLossBackward>)\n",
      "Loss after:25 iterations is :tensor(37.2899, grad_fn=<MseLossBackward>)\n",
      "Loss after:26 iterations is :tensor(3.1436, grad_fn=<MseLossBackward>)\n",
      "Loss after:27 iterations is :tensor(3.2423, grad_fn=<MseLossBackward>)\n",
      "Loss after:28 iterations is :tensor(9.5861, grad_fn=<MseLossBackward>)\n",
      "Loss after:29 iterations is :tensor(82.1541, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30 # or whatever\n",
    "batch_size = 128 # or whatever\n",
    "losses=[]\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # x is our input\n",
    "    permutation = torch.randperm(x.size()[0])\n",
    "\n",
    "    for i in range(0,x.size()[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = x[indices], y_target[indices]\n",
    "\n",
    "        # in case you wanted a semi-full example\n",
    "        outputs = core.forward(batch_x)\n",
    "        loss = loss_fn(outputs,batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    print(\"Loss after:\"+str(epoch)+\" iterations is :\"+ str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"No. of iterations\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0586, -0.0120, -0.1053,  ...,  0.0840, -0.0587, -0.0737],\n",
      "        [-0.0842, -0.1852, -0.0152,  ...,  0.1579, -0.0767,  0.1621],\n",
      "        [-0.0634,  0.1605,  0.0998,  ..., -0.2218, -0.0656, -0.0085],\n",
      "        ...,\n",
      "        [-0.1759,  0.0190, -0.0791,  ...,  0.0885, -0.2136, -0.1379],\n",
      "        [-0.1062, -0.2083,  0.0666,  ..., -0.1182,  0.1592, -0.1306],\n",
      "        [-0.0888, -0.1077,  0.0879,  ...,  0.2008,  0.1673, -0.0871]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1107, -0.0290,  0.1483,  0.0249, -0.1959,  0.0527, -0.2419,  0.0538,\n",
      "        -0.2712, -0.1888,  0.0980,  0.3665,  0.2266,  0.0654,  0.1612, -0.0082,\n",
      "         0.1656,  0.2458,  0.2162,  0.3557, -0.2545,  0.0130, -0.1783,  0.0829,\n",
      "        -0.1683, -0.1433, -0.2849, -0.0178,  0.1240, -0.2105, -0.0588, -0.2599,\n",
      "         0.1025, -0.0369, -0.1109, -0.0807, -0.1442,  0.2374,  0.0537,  0.0667,\n",
      "         0.0128, -0.0573, -0.3065, -0.2433, -0.0472,  0.1636,  0.1771, -0.1050,\n",
      "         0.1224,  0.2912, -0.1471,  0.0553,  0.0708,  0.0223,  0.2856,  0.0492,\n",
      "        -0.1676,  0.0455,  0.0074,  0.1440, -0.2375, -0.2916,  0.1239,  0.0097],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0748,  0.0894, -0.1333,  ..., -0.1047, -0.0043, -0.0820],\n",
      "        [-0.0345, -0.0542,  0.0315,  ...,  0.0990, -0.1030, -0.0643],\n",
      "        [ 0.0566, -0.0308, -0.2053,  ...,  0.0894, -0.3362, -0.0615],\n",
      "        ...,\n",
      "        [-0.0089, -0.0616, -0.0032,  ...,  0.0251, -0.0508,  0.0622],\n",
      "        [ 0.0700, -0.0450, -0.1601,  ..., -0.0580,  0.3402, -0.0716],\n",
      "        [-0.0085, -0.0026, -0.2395,  ...,  0.1799, -0.1527, -0.0467]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0593,  0.0908, -0.1278, -0.1166, -0.1125,  0.0619,  0.0552,  0.2673,\n",
      "        -0.0726,  0.1210, -0.1422, -0.0676,  0.0675,  0.2600, -0.1672,  0.2622,\n",
      "        -0.1405,  0.2604, -0.1231,  0.2359,  0.0808,  0.1407,  0.1197,  0.1370,\n",
      "        -0.1998, -0.1711, -0.1509,  0.0236,  0.1787, -0.0850, -0.0705, -0.0913,\n",
      "        -0.0652, -0.1018,  0.0953, -0.0728,  0.2877,  0.1842, -0.1141,  0.1801,\n",
      "         0.0365, -0.0959, -0.1361, -0.0007,  0.2005,  0.2528, -0.1793, -0.0447,\n",
      "        -0.0676,  0.1002, -0.0334,  0.1677,  0.1386, -0.1361, -0.0389, -0.0645,\n",
      "         0.1829, -0.1262,  0.1257, -0.1117, -0.0926, -0.1208,  0.1565, -0.0861],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0247, -0.0307, -0.2092, -0.1330,  0.0754, -0.1573, -0.1849,  0.3115,\n",
      "         -0.1600,  0.1686,  0.0893, -0.0461,  0.0886,  0.2477, -0.1378,  0.2624,\n",
      "         -0.1174,  0.2386,  0.0254,  0.2230, -0.1818,  0.1538,  0.0370,  0.2345,\n",
      "         -0.1079, -0.1086, -0.2107, -0.2034,  0.1906, -0.1160, -0.1739,  0.0378,\n",
      "         -0.1618, -0.1925,  0.1016, -0.2135,  0.1544,  0.2339, -0.1917,  0.1434,\n",
      "         -0.0224, -0.1904, -0.1302, -0.1011, -0.0411,  0.1603, -0.1055, -0.1828,\n",
      "         -0.1002,  0.0502, -0.1220,  0.1413,  0.1505, -0.0838, -0.0227, -0.0851,\n",
      "          0.1915, -0.0971,  0.0394, -0.1362, -0.2037,  0.0996,  0.1509, -0.1912],\n",
      "        [-0.0269,  0.1087,  0.1638,  0.1815, -0.0615,  0.2079,  0.1533, -0.1037,\n",
      "          0.0328,  0.0856,  0.0388,  0.2108, -0.0412,  0.0168, -0.0010, -0.0464,\n",
      "          0.2125, -0.0696, -0.0098,  0.0999,  0.1798, -0.0411,  0.1852, -0.0315,\n",
      "         -0.0057,  0.0557, -0.0421,  0.0472,  0.0425,  0.0443,  0.0266,  0.0314,\n",
      "          0.1354,  0.1884,  0.1621,  0.1043, -0.0712, -0.0192,  0.0743, -0.1813,\n",
      "         -0.0122,  0.1546,  0.0201,  0.1266,  0.2021, -0.0629,  0.0726,  0.1962,\n",
      "          0.1499, -0.0119, -0.0852, -0.0839, -0.0139, -0.0184, -0.1066,  0.1821,\n",
      "         -0.0648,  0.1753,  0.1994,  0.1489, -0.0158,  0.0421,  0.0609,  0.1592],\n",
      "        [ 0.0795, -0.1287,  0.1035,  0.1445,  0.0299,  0.1205,  0.1739,  0.0392,\n",
      "          0.0667, -0.0830,  0.1259,  0.0230, -0.0544, -0.0975,  0.0548, -0.1030,\n",
      "          0.0878, -0.0900, -0.0796, -0.0956,  0.0321, -0.2815,  0.0922, -0.0076,\n",
      "          0.1145,  0.1275, -0.0023,  0.1065, -0.2405,  0.1189,  0.0009,  0.0596,\n",
      "          0.0147,  0.0356, -0.0485,  0.1100, -0.1586, -0.0520, -0.0013, -0.1047,\n",
      "          0.0872,  0.1987,  0.0981, -0.0665, -0.1148, -0.1308,  0.1707,  0.1698,\n",
      "          0.0304, -0.0826, -0.0566, -0.2474, -0.1636,  0.1313,  0.0036,  0.1152,\n",
      "         -0.1945,  0.1001, -0.0057, -0.0352,  0.1283,  0.0956, -0.0681,  0.0252],\n",
      "        [-0.0809, -0.1037, -0.1219,  0.0438, -0.0316, -0.0469,  0.0555,  0.0516,\n",
      "         -0.1216,  0.2475, -0.0497,  0.1225,  0.2031,  0.1862, -0.0338,  0.0885,\n",
      "          0.0090,  0.1862, -0.1213, -0.0060,  0.0104,  0.1713,  0.1221,  0.0530,\n",
      "         -0.0173, -0.0840, -0.1069, -0.0669,  0.1806,  0.0492, -0.0199, -0.0785,\n",
      "          0.0902,  0.0284,  0.1944,  0.0217,  0.1990,  0.1528, -0.0713, -0.0236,\n",
      "          0.0852,  0.1225, -0.0573,  0.0630,  0.1716,  0.1176, -0.0820, -0.0312,\n",
      "         -0.0938,  0.1207,  0.1019,  0.1589, -0.0668,  0.0245, -0.0895, -0.0771,\n",
      "          0.1145,  0.0014,  0.2261,  0.0276, -0.0020, -0.0896,  0.2721,  0.0209]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0017, 0.0925, 0.0226, 0.1921], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.4321,  0.4843, -0.0337, -0.1447],\n",
      "        [ 0.0487,  0.0049, -0.3441,  0.4348],\n",
      "        [-0.4682,  0.0916,  0.3967, -0.0895],\n",
      "        [ 0.0968,  0.4444, -0.3924,  0.2528],\n",
      "        [ 0.4631,  0.2836,  0.2594,  0.1963],\n",
      "        [ 0.0053, -0.3080,  0.2327, -0.0336],\n",
      "        [-0.0030, -0.5176, -0.1183,  0.3728],\n",
      "        [-0.0566,  0.4229,  0.5118,  0.0047],\n",
      "        [-0.3348,  0.6204,  0.1961,  0.6085],\n",
      "        [ 0.2467,  0.1368,  0.0981,  0.2829],\n",
      "        [ 0.4453, -0.5016, -0.4508, -0.2988],\n",
      "        [ 0.4180, -0.3615,  0.4088, -0.3871],\n",
      "        [-0.4487,  0.4873, -0.1526,  0.4709],\n",
      "        [-0.3405,  0.1606,  0.3046,  0.0457],\n",
      "        [ 0.2176, -0.4294,  0.1378,  0.3949],\n",
      "        [-0.2375, -0.3296, -0.2439, -0.2341],\n",
      "        [-0.3993,  0.5278,  0.1620,  0.1442],\n",
      "        [ 0.3860,  0.3519, -0.0446,  0.3573],\n",
      "        [ 0.0449,  0.1564, -0.0601, -0.5080],\n",
      "        [-0.5666,  0.0193,  0.3483, -0.3600],\n",
      "        [-0.5803,  0.4717,  0.5708,  0.0486],\n",
      "        [ 0.4177, -0.3843, -0.1969,  0.0359],\n",
      "        [-0.2920,  0.1804, -0.3404,  0.2988],\n",
      "        [ 0.5835,  0.1122, -0.0082, -0.0958],\n",
      "        [ 0.1181,  0.3062, -0.3333, -0.1316],\n",
      "        [-0.1635, -0.1950, -0.1109,  0.4039],\n",
      "        [-0.3693, -0.0939,  0.5257,  0.1359],\n",
      "        [ 0.2768, -0.0197,  0.5250,  0.0501],\n",
      "        [-0.4710,  0.1169,  0.1169, -0.0529],\n",
      "        [ 0.3745,  0.0813,  0.1558,  0.4336],\n",
      "        [ 0.1712,  0.2526, -0.2074,  0.2580],\n",
      "        [ 0.0805, -0.6653, -0.2969,  0.2320]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.4334,  0.0564,  0.0392,  0.0195,  0.2302, -0.3273,  0.1919, -0.1703,\n",
      "        -0.4140, -0.1884, -0.3094, -0.2829, -0.4022, -0.2618,  0.4494, -0.0958,\n",
      "         0.3727,  0.3236, -0.5748, -0.2354, -0.4839, -0.6063, -0.3159, -0.0043,\n",
      "        -0.1810,  0.0559, -0.0537, -0.4674, -0.1977, -0.1216,  0.0123, -0.2285],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.8519e-01,  1.5788e-01,  2.4529e-01,  1.1159e-01, -1.3640e-01,\n",
      "          2.0746e-01,  5.1060e-02, -3.0597e-02,  3.2472e-01,  1.2003e-01,\n",
      "         -2.9175e-01,  1.9711e-01,  2.8129e-01,  1.7548e-01, -8.8379e-03,\n",
      "          5.9597e-02,  2.0546e-01, -1.1233e-01, -1.3764e-01,  9.7912e-02,\n",
      "          1.5522e-01, -6.5439e-02,  4.1728e-01, -1.9389e-01,  7.3173e-02,\n",
      "         -6.9583e-02,  7.7033e-02, -1.2509e-01, -2.0686e-04,  2.0513e-01,\n",
      "         -1.2125e-01,  6.9825e-02],\n",
      "        [ 5.5362e-02,  1.3178e-01,  1.7656e-01, -2.7919e-03, -4.2621e-02,\n",
      "          2.1170e-01,  1.0711e-01,  4.9474e-02,  1.3779e-01,  1.3108e-01,\n",
      "         -3.7938e-01, -2.7014e-02,  3.2682e-03,  2.2607e-01, -8.4380e-02,\n",
      "          9.2762e-02,  8.2989e-02,  1.3937e-01, -2.9101e-01, -5.1377e-02,\n",
      "          1.7509e-01, -1.2757e-01,  1.7129e-01, -2.6611e-01, -3.7295e-02,\n",
      "         -6.4479e-02,  2.8071e-01, -3.3849e-01,  1.8275e-02,  3.0323e-01,\n",
      "         -4.4520e-04, -1.1488e-01],\n",
      "        [ 4.9773e-02, -3.7380e-02, -1.6736e-01,  3.3324e-02, -6.0564e-02,\n",
      "          2.5542e-02,  1.3321e-01,  5.9078e-02,  2.1927e-02,  9.2468e-02,\n",
      "          1.2007e-01,  4.9987e-02,  2.3393e-02,  6.5716e-02, -5.7075e-02,\n",
      "         -1.3119e-01,  6.6623e-02,  1.1286e-01, -3.3426e-01,  6.4168e-02,\n",
      "         -1.5614e-01,  9.5846e-02, -1.8204e-01,  6.7774e-02, -9.9970e-02,\n",
      "         -2.2226e-01, -1.2303e-01, -6.3259e-02, -1.5751e-01,  1.1648e-01,\n",
      "          5.5714e-02, -3.4019e-02],\n",
      "        [-1.1866e-02,  2.1277e-01, -1.1000e-01, -1.7902e-01,  8.9877e-03,\n",
      "          1.0883e-01, -2.5441e-02,  1.3824e-01, -3.2412e-01, -1.8176e-01,\n",
      "         -3.2441e-02,  8.7451e-04, -1.5389e-01,  1.1523e-01, -5.2558e-02,\n",
      "          5.2725e-02,  3.2555e-02,  2.9082e-02, -3.8056e-01,  1.9024e-01,\n",
      "         -2.2230e-02,  2.3030e-01, -1.0029e-02, -4.0100e-02, -2.2575e-01,\n",
      "         -6.8157e-02,  1.9367e-01, -6.4635e-02, -4.3367e-02, -1.7538e-01,\n",
      "         -1.7609e-01,  2.5532e-01],\n",
      "        [-3.1980e-02, -1.4360e-01,  1.2370e-01, -1.6014e-01, -4.7721e-02,\n",
      "         -1.0981e-01, -2.2788e-03,  1.2504e-01,  1.3767e-01,  9.7585e-02,\n",
      "         -6.9489e-02, -1.5250e-01, -1.2359e-01, -6.9768e-02,  7.8591e-02,\n",
      "         -1.9432e-02,  1.2040e-03,  8.9675e-02, -1.6044e-01, -1.8861e-01,\n",
      "         -6.5043e-02,  1.1759e-01, -1.5513e-01, -2.5695e-02,  1.2755e-01,\n",
      "          1.1253e-02, -1.7485e-01,  1.7070e-01,  9.3397e-02, -1.0213e-01,\n",
      "          1.2690e-01, -8.3162e-02],\n",
      "        [-1.4049e-02, -8.1093e-02,  2.7754e-01, -8.1783e-02,  1.4746e-02,\n",
      "          2.5724e-01, -5.0799e-02,  2.2994e-01, -2.9407e-02, -1.9518e-01,\n",
      "         -5.2539e-02, -1.9445e-02,  1.0930e-01,  3.8346e-02, -1.9497e-01,\n",
      "          1.4274e-01,  2.1906e-01,  7.1497e-02, -1.5138e-01,  2.2405e-01,\n",
      "          2.3687e-02, -2.4131e-01,  2.9270e-01, -1.6757e-01, -9.6422e-02,\n",
      "         -3.4899e-02,  3.3343e-02, -2.1872e-01,  1.1579e-01,  1.4855e-01,\n",
      "          4.6023e-03,  3.2341e-01],\n",
      "        [ 2.0810e-01,  2.1802e-01,  4.4544e-02, -4.7691e-02,  6.8910e-02,\n",
      "         -5.2207e-02, -7.5426e-02,  1.8341e-01,  2.3617e-01, -9.2267e-02,\n",
      "         -3.9725e-01, -1.5104e-02,  3.0495e-01,  1.0606e-01,  5.3515e-02,\n",
      "         -4.4232e-02,  2.5674e-01, -4.0570e-02, -2.4998e-01,  2.2308e-01,\n",
      "          7.5679e-02, -9.7852e-02,  3.2405e-01,  2.6608e-02, -1.8763e-02,\n",
      "         -8.3321e-02,  2.2749e-01, -1.2529e-01,  2.0016e-01,  2.4694e-01,\n",
      "         -1.6638e-02, -1.1077e-01],\n",
      "        [-6.3505e-02,  4.3029e-02, -2.2539e-02,  1.8539e-02, -5.2667e-02,\n",
      "          1.6974e-01,  2.8513e-01, -2.0208e-01,  2.8523e-02, -3.1419e-01,\n",
      "          1.6267e-02,  2.7275e-01,  1.4986e-01, -5.4198e-02,  1.9562e-01,\n",
      "          7.3815e-02, -1.7969e-01,  1.2977e-03, -5.3060e-01, -1.0825e-01,\n",
      "         -1.7058e-01, -4.0148e-02, -1.6169e-01,  1.1173e-03, -6.3960e-01,\n",
      "          9.9683e-02, -1.4506e-01,  6.2672e-02,  7.8736e-02, -2.5054e-01,\n",
      "         -4.1317e-01,  4.1263e-01],\n",
      "        [ 1.8038e-01,  1.5631e-01, -7.5161e-02,  1.6126e-01,  1.4000e-01,\n",
      "         -1.3595e-01,  6.8022e-03,  1.0666e-01, -1.1580e-01,  5.2260e-02,\n",
      "          2.6031e-02, -2.0646e-02,  9.3083e-03, -4.4936e-02,  1.6478e-01,\n",
      "          4.6421e-02, -5.9595e-02,  1.1747e-01, -1.6575e-01,  1.0249e-01,\n",
      "         -1.4841e-01,  2.5366e-01, -1.4661e-01,  7.8434e-02,  2.3572e-02,\n",
      "         -1.3509e-01, -1.1208e-01, -8.3611e-02, -9.3022e-02,  1.2352e-01,\n",
      "         -6.2676e-02,  1.7364e-01],\n",
      "        [ 1.2977e-01,  1.0974e-01, -7.3173e-02, -3.5662e-02,  1.4225e-01,\n",
      "         -1.5781e-02,  1.1154e-01, -1.8392e-03, -8.2200e-03,  1.6184e-01,\n",
      "          1.2295e-02, -4.3538e-02,  2.9624e-03, -1.0552e-01, -8.0034e-02,\n",
      "         -9.2700e-02, -3.2725e-02,  1.7106e-01, -2.6873e-01,  1.8497e-01,\n",
      "         -1.2667e-01,  1.7279e-02, -2.1925e-01,  1.4580e-01, -3.6930e-02,\n",
      "          1.6198e-01, -1.1481e-01, -1.2759e-01, -1.9243e-02, -1.8076e-02,\n",
      "         -1.0829e-01, -5.7920e-02],\n",
      "        [ 2.0461e-01,  6.2264e-02,  1.3759e-01,  1.3935e-01,  3.3286e-02,\n",
      "          2.6186e-01, -2.4437e-01,  2.6639e-01,  2.8535e-01,  4.1311e-02,\n",
      "         -2.4919e-01, -2.8513e-02, -7.9608e-03,  1.9556e-01, -8.0319e-02,\n",
      "         -3.7276e-02,  2.5110e-01, -7.2523e-02, -1.8602e-01,  1.1324e-01,\n",
      "          3.0293e-01,  2.0185e-02,  3.1871e-01, -2.4646e-01,  1.4903e-01,\n",
      "          7.6121e-02,  4.7514e-02, -1.4001e-01,  1.9064e-01,  3.2792e-01,\n",
      "          1.0620e-01, -2.2553e-01],\n",
      "        [-1.1904e-01,  1.8668e-01, -1.3640e-01, -1.0684e-01,  1.8902e-02,\n",
      "          5.4318e-02,  5.5736e-02, -1.5646e-03,  1.6083e-03,  8.3287e-02,\n",
      "          8.9629e-02, -1.0592e-01,  9.5855e-03, -6.9022e-04,  1.7546e-01,\n",
      "         -2.1691e-01, -8.6392e-02,  5.2705e-02, -2.9669e-01, -1.8744e-01,\n",
      "          1.1865e-01,  1.4455e-01, -3.3438e-01, -5.4093e-02,  3.8115e-02,\n",
      "         -1.1361e-01,  9.7909e-02,  8.1702e-02, -1.5814e-01,  1.4557e-01,\n",
      "          1.0214e-01,  2.2947e-01],\n",
      "        [-1.1910e-01, -1.5817e-01,  1.1318e-01, -7.0371e-02, -3.5679e-04,\n",
      "         -3.6778e-02,  5.8424e-02,  4.4984e-02, -3.3730e-01, -3.2657e-02,\n",
      "         -7.1928e-03,  1.1521e-01,  3.3318e-02,  5.1050e-02,  6.6749e-02,\n",
      "          2.1213e-01,  9.4197e-02, -1.5470e-01, -4.2357e-01, -9.7395e-03,\n",
      "          4.8517e-03,  1.7228e-01, -1.0980e-01, -7.1438e-02, -6.8250e-02,\n",
      "          8.4093e-02,  1.3063e-01, -1.0891e-01, -5.5515e-02, -2.8499e-02,\n",
      "         -2.8520e-01,  3.3056e-01],\n",
      "        [ 1.7260e-01,  1.2493e-01,  1.9138e-01, -2.1107e-02,  6.2139e-02,\n",
      "          5.0177e-02,  1.6553e-01,  1.0456e-01,  3.1585e-01, -1.4057e-01,\n",
      "         -1.9454e-01, -6.6055e-04,  1.8653e-01,  2.2714e-01, -4.9748e-02,\n",
      "          1.9818e-01,  9.5190e-04, -1.4778e-01, -1.0393e-01,  1.1687e-01,\n",
      "          2.0332e-01,  2.3010e-02,  1.5523e-01, -6.4874e-02, -1.8353e-01,\n",
      "          1.1527e-01,  1.6483e-01, -2.1953e-01, -4.2044e-02,  2.2388e-01,\n",
      "         -1.5617e-01,  7.6846e-02],\n",
      "        [-3.6112e-02,  1.6869e-01, -2.5960e-02,  1.0292e-01, -1.5905e-01,\n",
      "          2.6445e-01, -1.0789e-01, -2.0679e-02,  1.2561e-01,  1.0700e-01,\n",
      "         -1.4999e-01,  1.8572e-01,  1.5968e-02,  2.6259e-01, -2.0201e-01,\n",
      "          3.2787e-02,  1.7665e-01, -2.0029e-01, -1.8389e-01,  5.1219e-02,\n",
      "          1.7558e-01, -2.2605e-01,  3.0240e-01, -1.8646e-01,  1.6090e-02,\n",
      "         -7.0491e-02,  1.8520e-01, -3.7827e-01,  2.8866e-01,  3.3742e-02,\n",
      "         -1.5085e-01,  1.9277e-01],\n",
      "        [-4.6993e-02, -1.6259e-01,  4.9828e-02, -1.0257e-02,  1.1772e-01,\n",
      "          9.9244e-02, -1.5583e-01,  7.8737e-02,  1.0348e-01, -7.1481e-02,\n",
      "         -5.5844e-02, -1.1593e-01,  5.8194e-02,  1.3619e-01, -1.8860e-01,\n",
      "          1.0726e-01, -1.3376e-01, -1.6222e-01, -1.0653e-01,  2.3608e-02,\n",
      "         -1.2098e-01,  3.9093e-02, -1.3842e-01,  1.1595e-01, -1.6710e-01,\n",
      "         -2.1257e-02, -3.1367e-02, -3.2414e-02, -8.3729e-02,  1.6775e-01,\n",
      "         -1.2855e-01, -4.7035e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1786,  0.0585,  0.0082, -0.1098,  0.0585, -0.0664,  0.1634,  0.0432,\n",
      "        -0.0604, -0.0296, -0.1473, -0.0838,  0.0720,  0.0821,  0.0903, -0.0271],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2831, -0.1621,  0.0365, -0.2379,  0.0208, -0.2081, -0.2766, -0.2078,\n",
      "          0.1754,  0.0711, -0.3431,  0.1190, -0.1530, -0.2935, -0.2162,  0.2063],\n",
      "        [-0.0634,  0.0119,  0.0643,  0.2265, -0.2590, -0.0594, -0.1716,  0.0107,\n",
      "         -0.2431, -0.0338,  0.1526,  0.0999,  0.3059, -0.0648, -0.1280,  0.2168]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2239,  0.0191], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.3286,  0.0298, -0.0735,  0.5548],\n",
      "        [ 0.0416, -0.1134, -0.1463, -0.0540],\n",
      "        [ 0.2395,  0.5359, -0.4725, -0.1629],\n",
      "        [-0.4843,  0.0905,  0.2594, -0.0415],\n",
      "        [-0.3930,  0.3841,  0.2416,  0.1551],\n",
      "        [-0.3570, -0.0394,  0.3329, -0.2659],\n",
      "        [ 0.0872,  0.1244,  0.2260,  0.2791],\n",
      "        [-0.3177, -0.0337,  0.2263, -0.2474],\n",
      "        [ 0.0665,  0.2322, -0.3518,  0.3573],\n",
      "        [-0.1455, -0.4196, -0.1382, -0.4189],\n",
      "        [-0.3335, -0.0433, -0.4228,  0.1265],\n",
      "        [ 0.2129,  0.2758, -0.2033,  0.4967],\n",
      "        [ 0.3032,  0.1450,  0.3640, -0.1872],\n",
      "        [ 0.6196, -0.7554, -0.1415,  0.4258],\n",
      "        [-0.5064, -0.1941, -0.3332, -0.1860],\n",
      "        [-0.0388,  0.3046,  0.1971, -0.0943],\n",
      "        [-0.2700,  0.0416,  0.1108,  0.0313],\n",
      "        [-0.2293, -0.1887, -0.2977,  0.4340],\n",
      "        [ 0.2277, -0.5594, -0.0657, -0.4989],\n",
      "        [ 0.0044, -0.1574,  0.5028, -0.2460],\n",
      "        [ 0.0189, -0.3491,  0.4201, -0.4559],\n",
      "        [ 0.0527, -0.2169,  0.4401,  0.3568],\n",
      "        [ 0.3415,  0.0487,  0.2738, -0.3900],\n",
      "        [-0.2753, -0.0528, -0.2673,  0.0023],\n",
      "        [-0.0064,  0.1174, -0.2375, -0.4264],\n",
      "        [ 0.0915,  0.3594, -0.3812,  0.3545],\n",
      "        [-0.3364,  0.4168,  0.0341, -0.1103],\n",
      "        [-0.1707,  0.1426, -0.2891, -0.3085],\n",
      "        [ 0.3037,  0.3263, -0.1194,  0.3285],\n",
      "        [-0.3371,  0.3842,  0.5105,  0.0564],\n",
      "        [-0.2951, -0.4245, -0.0931,  0.0504],\n",
      "        [ 0.4020,  0.3051, -0.0056, -0.4849]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2239,  0.3073,  0.0981, -0.3685,  0.2739, -0.3667,  0.1500, -0.4195,\n",
      "        -0.2812, -0.5957,  0.1427,  0.1313, -0.3268, -0.5052,  0.1420, -0.2779,\n",
      "        -0.1262,  0.4403, -0.1014,  0.2768, -0.0437, -0.4876, -0.1205, -0.4783,\n",
      "         0.4070,  0.2525, -0.4320, -0.4657,  0.3670, -0.1449, -0.4645, -0.6729],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1731, -0.1590, -0.1780,  ..., -0.0206, -0.0916,  0.1899],\n",
      "        [ 0.1173, -0.0342, -0.1572,  ...,  0.1809, -0.1127,  0.0509],\n",
      "        [-0.2661, -0.2268,  0.0939,  ...,  0.0325, -0.0522, -0.2649],\n",
      "        ...,\n",
      "        [-0.1051,  0.0797, -0.0994,  ...,  0.1209, -0.0527,  0.0606],\n",
      "        [ 0.1196,  0.0938, -0.0553,  ...,  0.0063, -0.0459,  0.5368],\n",
      "        [ 0.2240, -0.1394, -0.0012,  ...,  0.1744,  0.2021,  0.0487]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0320, -0.0613,  0.1292, -0.0275,  0.1624, -0.2336, -0.0397,  0.0312,\n",
      "        -0.0029, -0.2380, -0.0485, -0.0025, -0.2047, -0.0566, -0.0149, -0.0926,\n",
      "        -0.2653, -0.0376, -0.1835, -0.1034, -0.2215,  0.1433, -0.2474,  0.0785,\n",
      "         0.0293, -0.1897,  0.0719, -0.1480,  0.1000, -0.1428,  0.0405, -0.1567],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0584, -0.0666,  0.0964, -0.0006,  0.0187, -0.1985, -0.0640,  0.0144,\n",
      "         -0.1098,  0.0357, -0.2199,  0.1220, -0.1272, -0.1968,  0.1079, -0.2632,\n",
      "          0.0399, -0.0331, -0.0367,  0.0097,  0.0782,  0.0452, -0.0044,  0.1753,\n",
      "          0.0510, -0.1279, -0.0487, -0.0327, -0.1228,  0.1502, -0.1852, -0.1519],\n",
      "        [-0.2030, -0.0302, -0.1931, -0.0610, -0.2500,  0.1486, -0.1133, -0.0795,\n",
      "         -0.0141, -0.1451, -0.1073,  0.0055,  0.1060, -0.1188, -0.0731, -0.1286,\n",
      "          0.1991,  0.1299, -0.0753,  0.0472,  0.0105, -0.1361,  0.1300,  0.1683,\n",
      "         -0.2544, -0.1664,  0.0186, -0.1243,  0.1730,  0.0091, -0.1107, -0.0256],\n",
      "        [ 0.0469, -0.0548, -0.1415,  0.1389, -0.1090, -0.1223,  0.2114, -0.1659,\n",
      "         -0.0104,  0.2299,  0.0244, -0.0988,  0.0453, -0.1042,  0.0049,  0.1997,\n",
      "          0.1672, -0.0880,  0.0161,  0.2397,  0.0387, -0.0057,  0.1969, -0.1354,\n",
      "          0.0281,  0.0173, -0.0807,  0.1460,  0.1559,  0.0708, -0.0543,  0.1503],\n",
      "        [-0.0475,  0.1060,  0.0556, -0.0343,  0.0462, -0.1983, -0.0561, -0.0724,\n",
      "         -0.0120, -0.1105, -0.1877, -0.0600,  0.1112,  0.1473,  0.0778, -0.1212,\n",
      "          0.0564, -0.1210, -0.0721, -0.0956,  0.0349,  0.0191, -0.0991, -0.0857,\n",
      "          0.0581,  0.1096, -0.0276,  0.0263, -0.1495, -0.0864, -0.1218, -0.0390]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0271, -0.1419, -0.1861, -0.0025], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in core.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.iloc[190:200,2:-2]\n",
    "sample = torch.tensor(sample.values).float()\n",
    "sample.shape\n",
    "\n",
    "predict = core.forward(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-60.6324],\n",
       "        [-70.7927],\n",
       "        [  0.3685],\n",
       "        [  0.5835],\n",
       "        [  0.1920],\n",
       "        [  0.5596],\n",
       "        [  0.2232],\n",
       "        [  0.4025],\n",
       "        [  0.3756],\n",
       "        [  0.4399]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.0000e+01],\n",
       "        [-1.0000e+02],\n",
       "        [-8.1914e-12],\n",
       "        [-9.1015e-12],\n",
       "        [-1.0113e-11],\n",
       "        [-1.1236e-11],\n",
       "        [-1.2485e-11],\n",
       "        [-1.3872e-11],\n",
       "        [-1.5414e-11],\n",
       "        [-1.7126e-11]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target[190:200,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
